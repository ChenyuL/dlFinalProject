{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "TIJ5HEbYad7W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fadd484a-3357-40fe-bd8c-409550f51d16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l\r\u001b[K     |█████▊                          | 10 kB 31.3 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 20 kB 24.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 30 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 40 kB 9.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 51 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 57 kB 2.2 MB/s \n",
            "\u001b[?25h\u001b[?25l\r\u001b[K     |█████▌                          | 10 kB 35.0 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 20 kB 42.0 MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 30 kB 49.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 40 kB 52.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 51 kB 51.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 60 kB 4.8 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install kora -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "vGwDggQgayeQ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "import os\n",
        "import pickle\n",
        "import argparse\n",
        "from collections import defaultdict\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import gzip\n",
        "import shutil\n",
        "import spacy \n",
        "import pandas as pd \n",
        "from tqdm import tqdm\n",
        "from collections import Counter\n",
        "import kora.install.rdkit\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import Draw, MolFromSmiles, MolToSmiles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7z9bH-luwORy",
        "outputId": "110f2925-b9dd-40c6-83a6-8e1c5d3fdfcc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "ghzJaunWzhES"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import math\n",
        "import torch.nn as nn\n",
        "from rdkit import Chem\n",
        "from rdkit import rdBase\n",
        "rdBase.DisableLog('rdApp.*')\n",
        "\n",
        "def split(sm):\n",
        "    sm_couples = []\n",
        "    i = 0\n",
        "    while i < len(sm):\n",
        "        if i == len(sm) - 1:\n",
        "            sm_couples.append(sm[i])\n",
        "            i += 1\n",
        "        elif sm[i] == '%':\n",
        "            sm_couples.append(sm[i:i+3])\n",
        "            i += 3\n",
        "        elif sm[i:i+2] in set(['Cl', 'Ca', 'Cu', 'Br', 'Be', 'Ba', 'Bi', 'Si', 'Se', 'Sr', 'Na', 'Ni', 'Rb', 'Ra', 'Xe', 'Li', 'Al', ' As', 'Ag', 'Au',\\\n",
        "                            'Mg', 'Mn', 'Te', 'Zn', 'si', 'se', 'te', 'He', 'Kr', 'Fe', '+2', '+3', '+4', '-2', '-3', '-4']):\n",
        "            sm_couples.append(sm[i:i+2])\n",
        "            i += 2\n",
        "        else:\n",
        "            sm_couples.append(sm[i])\n",
        "            i += 1\n",
        "    return ' '.join(sm_couples)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGiLQlk4dhyf"
      },
      "source": [
        "# Smile Enumerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "mVj_F5rDdlGR"
      },
      "outputs": [],
      "source": [
        "class Iterator(object):\n",
        "    \"\"\"Abstract base class for data iterators.\n",
        "    # Arguments\n",
        "        n: Integer, total number of samples in the dataset to loop over.\n",
        "        batch_size: Integer, size of a batch.\n",
        "        shuffle: Boolean, whether to shuffle the data between epochs.\n",
        "        seed: Random seeding for data shuffling.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, n, batch_size, shuffle, seed):\n",
        "        self.n = n\n",
        "        self.batch_size = batch_size\n",
        "        self.shuffle = shuffle\n",
        "        self.batch_index = 0\n",
        "        self.total_batches_seen = 0\n",
        "        self.index_generator = self._flow_index(n, batch_size, shuffle, seed)\n",
        "        if n < batch_size:\n",
        "            raise ValueError('Input data length is shorter than batch_size\\nAdjust batch_size')\n",
        "\n",
        "    def reset(self):\n",
        "        self.batch_index = 0\n",
        "\n",
        "    def _flow_index(self, n, batch_size=32, shuffle=False, seed=None):\n",
        "        # Ensure self.batch_index is 0.\n",
        "        self.reset()\n",
        "        while 1:\n",
        "            if seed is not None:\n",
        "                np.random.seed(seed + self.total_batches_seen)\n",
        "            if self.batch_index == 0:\n",
        "                index_array = np.arange(n)\n",
        "                if shuffle:\n",
        "                    index_array = np.random.permutation(n)\n",
        "\n",
        "            current_index = (self.batch_index * batch_size) % n\n",
        "            if n > current_index + batch_size:\n",
        "                current_batch_size = batch_size\n",
        "                self.batch_index += 1\n",
        "            else:\n",
        "                current_batch_size = n - current_index\n",
        "                self.batch_index = 0\n",
        "            self.total_batches_seen += 1\n",
        "            yield (index_array[current_index: current_index + current_batch_size],\n",
        "                   current_index, current_batch_size)\n",
        "\n",
        "    def __iter__(self):\n",
        "        # Needed if we want to do something like:\n",
        "        # for x, y in data_gen.flow(...):\n",
        "        return self\n",
        "\n",
        "    def __next__(self, *args, **kwargs):\n",
        "        return self.next(*args, **kwargs)\n",
        "\n",
        "class SmilesIterator(Iterator):\n",
        "    \"\"\"Iterator yielding data from a SMILES array.\n",
        "    # Arguments\n",
        "        x: Numpy array of SMILES input data.\n",
        "        y: Numpy array of targets data.\n",
        "        smiles_data_generator: Instance of `SmilesEnumerator`\n",
        "            to use for random SMILES generation.\n",
        "        batch_size: Integer, size of a batch.\n",
        "        shuffle: Boolean, whether to shuffle the data between epochs.\n",
        "        seed: Random seed for data shuffling.\n",
        "        dtype: dtype to use for returned batch. Set to keras.backend.floatx if using Keras\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, x, y, smiles_data_generator,\n",
        "                 batch_size=32, shuffle=False, seed=None,\n",
        "                 dtype=np.float32\n",
        "                 ):\n",
        "        if y is not None and len(x) != len(y):\n",
        "            raise ValueError('X (images tensor) and y (labels) '\n",
        "                             'should have the same length. '\n",
        "                             'Found: X.shape = %s, y.shape = %s' %\n",
        "                             (np.asarray(x).shape, np.asarray(y).shape))\n",
        "\n",
        "        self.x = np.asarray(x)\n",
        "\n",
        "        if y is not None:\n",
        "            self.y = np.asarray(y)\n",
        "        else:\n",
        "            self.y = None\n",
        "        self.smiles_data_generator = smiles_data_generator\n",
        "        self.dtype = dtype\n",
        "        super(SmilesIterator, self).__init__(x.shape[0], batch_size, shuffle, seed)\n",
        "\n",
        "    def next(self):\n",
        "        \"\"\"For python 2.x.\n",
        "        # Returns\n",
        "            The next batch.\n",
        "        \"\"\"\n",
        "        # Keeps under lock only the mechanism which advances\n",
        "        # the indexing of each batch.\n",
        "        index_array, current_index, current_batch_size = next(self.index_generator)\n",
        "        # The transformation of images is not under thread lock\n",
        "        # so it can be done in parallel\n",
        "        batch_x = np.zeros(tuple([current_batch_size] + [ self.smiles_data_generator.pad, self.smiles_data_generator._charlen]), dtype=self.dtype)\n",
        "        for i, j in enumerate(index_array):\n",
        "            smiles = self.x[j:j+1]\n",
        "            x = self.smiles_data_generator.transform(smiles)\n",
        "            batch_x[i] = x\n",
        "\n",
        "        if self.y is None:\n",
        "            return batch_x\n",
        "        batch_y = self.y[index_array]\n",
        "        return batch_x, batch_y\n",
        "\n",
        "\n",
        "class SmilesEnumerator(object):\n",
        "    \"\"\"SMILES Enumerator, vectorizer and devectorizer\n",
        "    \n",
        "    #Arguments\n",
        "        charset: string containing the characters for the vectorization\n",
        "          can also be generated via the .fit() method\n",
        "        pad: Length of the vectorization\n",
        "        leftpad: Add spaces to the left of the SMILES\n",
        "        isomericSmiles: Generate SMILES containing information about stereogenic centers\n",
        "        enum: Enumerate the SMILES during transform\n",
        "        canonical: use canonical SMILES during transform (overrides enum)\n",
        "    \"\"\"\n",
        "    def __init__(self, charset = '@C)(=cOn1S2/H[N]\\\\', pad=120, leftpad=True, isomericSmiles=True, enum=True, canonical=False):\n",
        "        self._charset = None\n",
        "        self.charset = charset\n",
        "        self.pad = pad\n",
        "        self.leftpad = leftpad\n",
        "        self.isomericSmiles = isomericSmiles\n",
        "        self.enumerate = enum\n",
        "        self.canonical = canonical\n",
        "\n",
        "    @property\n",
        "    def charset(self):\n",
        "        return self._charset\n",
        "        \n",
        "    @charset.setter\n",
        "    def charset(self, charset):\n",
        "        self._charset = charset\n",
        "        self._charlen = len(charset)\n",
        "        self._char_to_int = dict((c,i) for i,c in enumerate(charset))\n",
        "        self._int_to_char = dict((i,c) for i,c in enumerate(charset))\n",
        "        \n",
        "    def fit(self, smiles, extra_chars=[], extra_pad = 5):\n",
        "        \"\"\"Performs extraction of the charset and length of a SMILES datasets and sets self.pad and self.charset\n",
        "        \n",
        "        #Arguments\n",
        "            smiles: Numpy array or Pandas series containing smiles as strings\n",
        "            extra_chars: List of extra chars to add to the charset (e.g. \"\\\\\\\\\" when \"/\" is present)\n",
        "            extra_pad: Extra padding to add before or after the SMILES vectorization\n",
        "        \"\"\"\n",
        "        charset = set(\"\".join(list(smiles)))\n",
        "        self.charset = \"\".join(charset.union(set(extra_chars)))\n",
        "        self.pad = max([len(smile) for smile in smiles]) + extra_pad\n",
        "        \n",
        "    def randomize_smiles(self, smiles):\n",
        "        \"\"\"Perform a randomization of a SMILES string\n",
        "        must be RDKit sanitizable\"\"\"\n",
        "        m = Chem.MolFromSmiles(smiles)\n",
        "        if m is None:\n",
        "          return None\n",
        "        ans = list(range(m.GetNumAtoms()))\n",
        "        np.random.shuffle(ans)\n",
        "        nm = Chem.RenumberAtoms(m,ans)\n",
        "        return Chem.MolToSmiles(nm, canonical=self.canonical, isomericSmiles=self.isomericSmiles)\n",
        "\n",
        "    def transform(self, smiles):\n",
        "        \"\"\"Perform an enumeration (randomization) and vectorization of a Numpy array of smiles strings\n",
        "        #Arguments\n",
        "            smiles: Numpy array or Pandas series containing smiles as strings\n",
        "        \"\"\"\n",
        "        one_hot =  np.zeros((smiles.shape[0], self.pad, self._charlen),dtype=np.int8)\n",
        "        \n",
        "        if self.leftpad:\n",
        "            for i,ss in enumerate(smiles):\n",
        "                if self.enumerate: ss = self.randomize_smiles(ss)\n",
        "                l = len(ss)\n",
        "                diff = self.pad - l\n",
        "                for j,c in enumerate(ss):\n",
        "                    one_hot[i,j+diff,self._char_to_int[c]] = 1\n",
        "            return one_hot\n",
        "        else:\n",
        "            for i,ss in enumerate(smiles):\n",
        "                if self.enumerate: ss = self.randomize_smiles(ss)\n",
        "                for j,c in enumerate(ss):\n",
        "                    one_hot[i,j,self._char_to_int[c]] = 1\n",
        "            return one_hot\n",
        "\n",
        "      \n",
        "    def reverse_transform(self, vect):\n",
        "        \"\"\" Performs a conversion of a vectorized SMILES to a smiles strings\n",
        "        charset must be the same as used for vectorization.\n",
        "        #Arguments\n",
        "            vect: Numpy array of vectorized SMILES.\n",
        "        \"\"\"       \n",
        "        smiles = []\n",
        "        for v in vect:\n",
        "            #mask v \n",
        "            v=v[v.sum(axis=1)==1]\n",
        "            #Find one hot encoded index with argmax, translate to char and join to string\n",
        "            smile = \"\".join(self._int_to_char[i] for i in v.argmax(axis=1))\n",
        "            smiles.append(smile)\n",
        "        return np.array(smiles)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u0noJGmZ0NTa"
      },
      "source": [
        "# Data Loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "hHrTe_ZscXwN"
      },
      "outputs": [],
      "source": [
        "class Randomizer(object):\n",
        "    def __init__(self):\n",
        "        self.smile_enum = SmilesEnumerator()\n",
        "    \n",
        "    def __call__(self, smile):\n",
        "        random_smile = self.smile_enum.randomize_smiles(smile)\n",
        "        if random_smile is None:\n",
        "            sm_spaced = split(smile)\n",
        "        else:\n",
        "            sm_spaced = split(random_smile)\n",
        "        sm_split = sm_spaced.split()\n",
        "\n",
        "        if len(sm_split) <= 218:\n",
        "            return sm_split\n",
        "        else:\n",
        "            return split(sm).split()\n",
        "\n",
        "    def random_transform(self, sm):\n",
        "        return self.smile_enum.randomize_smiles(sm)\n",
        "\n",
        "class MyDataset(Dataset):\n",
        "    def __init__(self, smiles, vocab, seq_len=220, random=Randomizer()):\n",
        "        self.smiles = smiles\n",
        "        self.vocab = vocab\n",
        "        self.seq_len = seq_len\n",
        "        self.random = random\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.smiles)\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        sm = self.smiles[item]\n",
        "        if sm is None:\n",
        "          return None\n",
        "        sm = self.random(sm)\n",
        "        content = [self.vocab.word_dict.get(token, self.vocab.unk_index) for token in sm]\n",
        "        X = [self.vocab.sos_index] + content + [self.vocab.eos_index]\n",
        "        padding = [self.vocab.pad_index] * (self.seq_len - len(X))\n",
        "        X.extend(padding)\n",
        "        return torch.tensor(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oISuFNuA13OC"
      },
      "source": [
        "Build Vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "rbcEQ3ro15D5"
      },
      "outputs": [],
      "source": [
        "class Vocab(object):\n",
        "    def __init__(self, texts, min_freq):\n",
        "        self.pad_index = 0\n",
        "        self.unk_index = 1\n",
        "        self.eos_index = 2\n",
        "        self.sos_index = 3\n",
        "        self.mask_index = 4\n",
        "\n",
        "        counter = Counter()\n",
        "        \n",
        "        self.words = [\"<pad>\", \"<unk>\", \"<eos>\", \"<sos>\", \"<mask>\"]\n",
        "\n",
        "        for line in texts:\n",
        "            if isinstance(line, list):\n",
        "                words = line\n",
        "            else:\n",
        "                words = line.replace(\"\\t\", \"\").replace(\"\\n\", \"\").split()\n",
        "\n",
        "            for word in words:\n",
        "                if word not in self.words:\n",
        "                    counter[word] += 1\n",
        "\n",
        "        freq_list = counter.most_common()\n",
        "        \n",
        "        for word, freq in freq_list:\n",
        "            if freq < min_freq:\n",
        "                break\n",
        "            self.words.append(word)\n",
        "\n",
        "        self.word_dict = {tok: i for i, tok in enumerate(self.words)}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.words)\n",
        "\n",
        "    def extend(self, vocab_new, sort=False):\n",
        "        words_new = sorted(vocab_new.words) if sort else vocab_new.words\n",
        "        for w in words_new:\n",
        "            if w not in self.words:\n",
        "                self.words.append(w)\n",
        "                self.words_dict[w] = len(self.words) - 1\n",
        "\n",
        "    def load_vocab(vocab_path: str):\n",
        "        with open(vocab_path, \"rb\") as f:\n",
        "            return pickle.load(f)\n",
        "\n",
        "    def save_vocab(self, vocab_path):\n",
        "        with open(vocab_path, \"wb\") as f:\n",
        "            pickle.dump(self, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "F_FKfauNl8Ll"
      },
      "outputs": [],
      "source": [
        "PAD = 0\n",
        "UNK = 1\n",
        "EOS = 2\n",
        "SOS = 3\n",
        "MASK = 4\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, dropout = 0.1, max_len = 5000):\n",
        "        super().__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        position = torch.arange(max_len).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
        "        pe = torch.zeros(max_len, 1, d_model)\n",
        "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.pe[:x.size(0)]\n",
        "        return self.dropout(x)\n",
        "\n",
        "class SmTrfm(nn.Module):\n",
        "    def __init__(self, in_size, hidden_size, out_size, n_layers, dropout=0.1):\n",
        "        super(TrfmSeq2seq, self).__init__()\n",
        "        self.in_size = in_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.embed = nn.Embedding(in_size, hidden_size)\n",
        "        self.pe = PositionalEncoding(hidden_size, dropout)\n",
        "        self.trfm = nn.Transformer(d_model=hidden_size, nhead=4, \n",
        "        num_encoder_layers=n_layers, num_decoder_layers=n_layers, dim_feedforward=hidden_size)\n",
        "        self.out = nn.Linear(hidden_size, out_size)\n",
        "\n",
        "    def forward(self, src):\n",
        "        embedded = self.embed(src)\n",
        "        embedded += self.pe(embedded)\n",
        "        hidden = self.trfm(embedded, embedded)\n",
        "        out = self.out(hidden)\n",
        "        out = F.log_softmax(out, dim=2)\n",
        "        return out\n",
        "\n",
        "    def _encode(self, src):\n",
        "        embedded = self.embed(src)\n",
        "        embedded = self.pe(embedded)\n",
        "        output = embedded\n",
        "        for i in range(self.trfm.encoder.num_layers - 1):\n",
        "            output = self.trfm.encoder.layers[i](output, None)\n",
        "        penul = output.detach().numpy()\n",
        "        output = self.trfm.encoder.layers[-1](output, None)\n",
        "        if self.trfm.encoder.norm:\n",
        "            output = self.trfm.encoder.norm(output)\n",
        "        output = output.detach().numpy()\n",
        "        \n",
        "        return np.hstack([np.mean(output, axis=0), np.max(output, axis=0), output[0,:,:], penul[0,:,:]])\n",
        "    \n",
        "    def encode(self, src):\n",
        "        batch_size = src.shape[1]\n",
        "        if batch_size <= 100:\n",
        "            return self._encode(src)\n",
        "        else: # Batch is too large to load\n",
        "            i = 0\n",
        "            while i < batch_size:\n",
        "                if o == 0:\n",
        "                    out = self._encode(src[:, i:i+100])\n",
        "                else:\n",
        "                    out = np.concatenate([out, self._encode(src[:, i:i+100])], axis=0)\n",
        "                i += 100\n",
        "            return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "0Tw7NWhFQVjB"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class SandwichTransformer(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model = 512, nhead = 8, num_encoder_layers = 6,\n",
        "                 num_decoder_layers = 6, dim_feedforward = 2048, dropout = 0.1,\n",
        "                 sandwich_k = 2, sandwich_encoder = False, sandwich_decoder = False,\n",
        "                 activation = F.relu, layer_norm_eps = 1e-5):\n",
        "        super(SandwichTransformer, self).__init__()\n",
        "\n",
        "        encoder_layer = TransformerEncoderLayer(d_model, nhead, dim_feedforward, dropout,\n",
        "                                                activation, layer_norm_eps)\n",
        "        encoder_norm = nn.LayerNorm(d_model, eps=layer_norm_eps)\n",
        "        self.encoder = TransformerEncoder(encoder_layer, num_encoder_layers, encoder_norm, sandwich_k if sandwich_encoder else 0)\n",
        "\n",
        "        decoder_layer = TransformerDecoderLayer(d_model, nhead, dim_feedforward, dropout,\n",
        "                                                activation, layer_norm_eps)\n",
        "        decoder_norm = nn.LayerNorm(d_model, eps=layer_norm_eps)\n",
        "        self.decoder = TransformerDecoder(decoder_layer, num_decoder_layers, decoder_norm, sandwich_k if sandwich_decoder else 0)\n",
        "\n",
        "        self._reset_parameters()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.nhead = nhead\n",
        "\n",
        "        self.sandwich_k = sandwich_k\n",
        "        self.sandwich_encoder = sandwich_encoder\n",
        "        self.sandwich_decoder = sandwich_decoder\n",
        "\n",
        "    def forward(self, src, tgt, src_mask = None, tgt_mask = None, memory_mask = None,\n",
        "                src_key_padding_mask = None, tgt_key_padding_mask = None,\n",
        "                memory_key_padding_mask = None):\n",
        "\n",
        "        is_batched = src.dim() == 3\n",
        "\n",
        "        memory = self.encoder(src, mask=src_mask, src_key_padding_mask=src_key_padding_mask, )\n",
        "        output = self.decoder(tgt, memory, tgt_mask=tgt_mask, memory_mask=memory_mask,\n",
        "                              tgt_key_padding_mask=tgt_key_padding_mask,\n",
        "                              memory_key_padding_mask=memory_key_padding_mask)\n",
        "        return output\n",
        "\n",
        "\n",
        "    def generate_square_subsequent_mask(sz):\n",
        "        return torch.triu(torch.full((sz, sz), float('-inf')), diagonal=1)\n",
        "\n",
        "    def _reset_parameters(self):\n",
        "        for p in self.parameters():\n",
        "            if p.dim() > 1:\n",
        "                nn.init.xavier_uniform_(p)\n",
        "\n",
        "class TransformerEncoder(nn.Module):\n",
        "    _constants_ = ['norm']\n",
        "    def __init__(self, encoder_layer, num_layers, norm=None, sandwich_k=0):\n",
        "        super(TransformerEncoder, self).__init__()\n",
        "        self.layers = _get_clones(encoder_layer, num_layers+sandwich_k)\n",
        "        self.num_layers = num_layers+sandwich_k\n",
        "        self.norm = norm\n",
        "        self.sandwich_k = sandwich_k\n",
        "\n",
        "    def forward(self, src, mask = None, src_key_padding_mask = None):\n",
        "        output = src\n",
        "        for i, mod in enumerate(self.layers):\n",
        "            if i < self.sandwich_k:\n",
        "                output = mod(output, src_mask=mask, src_key_padding_mask=src_key_padding_mask, layer_type=1)\n",
        "            elif i >= self.num_layers - self.sandwich_k:\n",
        "                output = mod(output, src_mask=mask, src_key_padding_mask=src_key_padding_mask, layer_type=2)\n",
        "            else:\n",
        "                output = mod(output, src_mask=mask, src_key_padding_mask=src_key_padding_mask, layer_type=0)\n",
        "\n",
        "        if self.norm is not None:\n",
        "            output = self.norm(output)\n",
        "\n",
        "        return output\n",
        "\n",
        "class TransformerDecoder(nn.Module):\n",
        "    _constants_ = ['norm']\n",
        "\n",
        "    def __init__(self, decoder_layer, num_layers, norm=None, sandwich_k=0):\n",
        "        super(TransformerDecoder, self).__init__()\n",
        "        self.layers = _get_clones(decoder_layer, num_layers+sandwich_k)\n",
        "        self.num_layers = num_layers+sandwich_k\n",
        "        self.norm = norm\n",
        "        self.sandwich_k = sandwich_k\n",
        "\n",
        "    def forward(self, tgt, memory, tgt_mask = None,\n",
        "                memory_mask = None, tgt_key_padding_mask = None,\n",
        "                memory_key_padding_mask = None):\n",
        "        output = tgt\n",
        "\n",
        "        for i, mod in enumerate(self.layers):\n",
        "            if i < self.sandwich_k:\n",
        "                output = mod(output, memory, tgt_mask=tgt_mask,\n",
        "                      memory_mask=memory_mask,\n",
        "                      tgt_key_padding_mask=tgt_key_padding_mask,\n",
        "                      memory_key_padding_mask=memory_key_padding_mask, layer_type=1)\n",
        "            elif i >= self.num_layers - self.sandwich_k:\n",
        "                output = mod(output, memory, tgt_mask=tgt_mask,\n",
        "                      memory_mask=memory_mask,\n",
        "                      tgt_key_padding_mask=tgt_key_padding_mask,\n",
        "                      memory_key_padding_mask=memory_key_padding_mask, layer_type=2)\n",
        "            else:\n",
        "                output = mod(output, memory, tgt_mask=tgt_mask,\n",
        "                      memory_mask=memory_mask,\n",
        "                      tgt_key_padding_mask=tgt_key_padding_mask,\n",
        "                      memory_key_padding_mask=memory_key_padding_mask, layer_type=0)\n",
        "\n",
        "        if self.norm is not None:\n",
        "            output = self.norm(output)\n",
        "\n",
        "        return output\n",
        "\n",
        "class TransformerEncoderLayer(nn.Module):\n",
        "    _constants_ = ['batch_first', 'norm_first']\n",
        "\n",
        "    def __init__(self, d_model, nhead, dim_feedforward = 2048, dropout = 0.1,\n",
        "                 activation = F.relu, layer_norm_eps = 1e-5):\n",
        "        super(TransformerEncoderLayer, self).__init__()\n",
        "        self.self_attn = nn.MultiheadAttention(d_model, nhead, dropout=dropout)\n",
        "        # Implementation of Feedforward model\n",
        "        self.linear1 = nn.Linear(d_model, dim_feedforward)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.linear2 = nn.Linear(dim_feedforward, d_model)\n",
        "\n",
        "        self.norm1 = nn.LayerNorm(d_model, eps=layer_norm_eps)\n",
        "        self.norm2 = nn.LayerNorm(d_model, eps=layer_norm_eps)\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "\n",
        "        self.activation = activation\n",
        "\n",
        "    def _setstate_(self, state):\n",
        "        if 'activation' not in state:\n",
        "            state['activation'] = F.relu\n",
        "        super(TransformerEncoderLayer, self)._setstate_(state)\n",
        "\n",
        "    def forward(self, src, src_mask = None, src_key_padding_mask = None,\n",
        "                layer_type=0):\n",
        "        x = src\n",
        "\n",
        "        if layer_type == 0:\n",
        "            x = self.norm1(x + self._sa_block(x, src_mask, src_key_padding_mask))\n",
        "            x = self.norm2(x + self._ff_block(x))\n",
        "        elif layer_type == 1:\n",
        "            x = self.norm1(x + self._sa_block(x, src_mask, src_key_padding_mask))\n",
        "        else:\n",
        "            x = self.norm2(x + self._ff_block(x))\n",
        "\n",
        "        return x\n",
        "\n",
        "    # self-attention block\n",
        "    def _sa_block(self, x, attn_mask, key_padding_mask):\n",
        "        x = self.self_attn(x, x, x,\n",
        "                           attn_mask=attn_mask,\n",
        "                           key_padding_mask=key_padding_mask,\n",
        "                           need_weights=False)[0]\n",
        "        return self.dropout1(x)\n",
        "\n",
        "    # feed forward block\n",
        "    def _ff_block(self, x):\n",
        "        x = self.linear2(self.dropout(self.activation(self.linear1(x))))\n",
        "        return self.dropout2(x)\n",
        "\n",
        "class TransformerDecoderLayer(nn.Module):\n",
        "    _constants_ = ['batch_first', 'norm_first']\n",
        "\n",
        "    def __init__(self, d_model, nhead, dim_feedforward = 2048, dropout = 0.1,\n",
        "                 activation = F.relu, layer_norm_eps = 1e-5):\n",
        "      \n",
        "        super(TransformerDecoderLayer, self).__init__()\n",
        "        self.self_attn = nn.MultiheadAttention(d_model, nhead, dropout=dropout)\n",
        "        self.multihead_attn = nn.MultiheadAttention(d_model, nhead, dropout=dropout)\n",
        "        # Implementation of Feedforward model\n",
        "        self.linear1 = nn.Linear(d_model, dim_feedforward)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.linear2 = nn.Linear(dim_feedforward, d_model)\n",
        "\n",
        "        self.norm1 = nn.LayerNorm(d_model, eps=layer_norm_eps)\n",
        "        self.norm2 = nn.LayerNorm(d_model, eps=layer_norm_eps)\n",
        "        self.norm3 = nn.LayerNorm(d_model, eps=layer_norm_eps)\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "        self.dropout3 = nn.Dropout(dropout)\n",
        "\n",
        "        self.activation = activation\n",
        "\n",
        "    def _setstate_(self, state):\n",
        "        if 'activation' not in state:\n",
        "            state['activation'] = F.relu\n",
        "        super(TransformerDecoderLayer, self)._setstate_(state)\n",
        "\n",
        "    def forward(self, tgt, memory, tgt_mask = None, memory_mask= None,\n",
        "                tgt_key_padding_mask = None, memory_key_padding_mask = None,\n",
        "                layer_type = 0):\n",
        "        x = tgt\n",
        "        if layer_type == 0:\n",
        "            x = self.norm1(x + self._sa_block(x, tgt_mask, tgt_key_padding_mask))\n",
        "            x = self.norm2(x + self._mha_block(x, memory, memory_mask, memory_key_padding_mask))\n",
        "            x = self.norm3(x + self._ff_block(x))\n",
        "        elif layer_type == 1:\n",
        "            x = self.norm1(x + self._sa_block(x, tgt_mask, tgt_key_padding_mask))\n",
        "            x = self.norm2(x + self._mha_block(x, memory, memory_mask, memory_key_padding_mask))\n",
        "        else:\n",
        "            x = self.norm3(x + self._ff_block(x))\n",
        "\n",
        "        return x\n",
        "\n",
        "    # self-attention block\n",
        "    def _sa_block(self, x, attn_mask , key_padding_mask):\n",
        "        x = self.self_attn(x, x, x,\n",
        "                           attn_mask=attn_mask,\n",
        "                           key_padding_mask=key_padding_mask,\n",
        "                           need_weights=False)[0]\n",
        "        return self.dropout1(x)\n",
        "\n",
        "    # multihead attention block\n",
        "    def _mha_block(self, x, mem, attn_mask, key_padding_mask):\n",
        "        x = self.multihead_attn(x, mem, mem,\n",
        "                                attn_mask=attn_mask,\n",
        "                                key_padding_mask=key_padding_mask,\n",
        "                                need_weights=False)[0]\n",
        "        return self.dropout2(x)\n",
        "\n",
        "    # feed forward block\n",
        "    def _ff_block(self, x):\n",
        "        x = self.linear2(self.dropout(self.activation(self.linear1(x))))\n",
        "        return self.dropout3(x)\n",
        "\n",
        "def _get_clones(module, N):\n",
        "    return nn.ModuleList([copy.deepcopy(module) for i in range(N)])\n",
        "\n",
        "def _get_activation_fn(activation):\n",
        "    if activation == \"relu\":\n",
        "        return F.relu\n",
        "    elif activation == \"gelu\":\n",
        "        return F.gelu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMQOb6WM1hUI"
      },
      "source": [
        "Pre-Trained Transformer Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "ek__RieB1n_i"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "import math\n",
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torch.autograd import Variable\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "\n",
        "PAD = 0\n",
        "UNK = 1\n",
        "EOS = 2\n",
        "SOS = 3\n",
        "MASK = 4\n",
        "\n",
        "class SandwichSmTrfm(nn.Module):\n",
        "    def __init__(self, in_size, hidden_size, out_size, n_layers, sandwich_k, sandwich_encoder, sandwich_decoder):\n",
        "        super(SandwichSmTrfm, self).__init__()\n",
        "        self.in_size = in_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.embed = nn.Embedding(in_size, hidden_size)\n",
        "        self.pe = PositionalEncoding(hidden_size, 0.1)\n",
        "        self.sandwich_k = sandwich_k\n",
        "        self.sandwich_encoder = sandwich_encoder\n",
        "        self.sandwich_decoder = sandwich_decoder\n",
        "        self.trfm = SandwichTransformer(d_model=hidden_size, nhead=4, \n",
        "        num_encoder_layers=n_layers, num_decoder_layers = n_layers, dim_feedforward=hidden_size,\n",
        "        sandwich_k=sandwich_k, sandwich_encoder=sandwich_encoder, sandwich_decoder=sandwich_decoder,\n",
        "        dropout=0.4)\n",
        "        self.out = nn.Linear(hidden_size, out_size)\n",
        "\n",
        "    def forward(self, src):\n",
        "        embedded = self.embed(src)\n",
        "        embedded += self.pe(embedded)\n",
        "        hidden = self.trfm(embedded, embedded)\n",
        "        out = self.out(hidden)\n",
        "        out = F.log_softmax(out, dim=2)\n",
        "        return out\n",
        "\n",
        "    def _encode(self, src):\n",
        "        embedded = self.embed(src)\n",
        "        embedded = self.pe(embedded)\n",
        "        output = embedded\n",
        "        if self.sandwich_encoder:\n",
        "            for i in range(self.trfm.encoder.num_layers - 1):\n",
        "                if i < self.sandwich_k:\n",
        "                    output = self.trfm.encoder.layers[i](output, None, layer_type=1)\n",
        "                elif i >= self.trfm.encoder.num_layers - self.sandwich_k:\n",
        "                    output = self.trfm.encoder.layers[i](output, None, layer_type=2)\n",
        "                else:\n",
        "                    output = self.trfm.encoder.layers[i](output, None, layer_type=0)\n",
        "            penul = output.cpu().detach().numpy()\n",
        "            output = self.trfm.encoder.layers[-1](output, None, layer_type=2)\n",
        "        else:\n",
        "            for i in range(self.trfm.encoder.num_layers - 1):\n",
        "                output = self.trfm.encoder.layers[i](output, None, layer_type=0)\n",
        "            penul = output.cpu().detach().numpy()\n",
        "            output = self.trfm.encoder.layers[-1](output, None, layer_type=0)\n",
        "        if self.trfm.encoder.norm:\n",
        "            output = self.trfm.encoder.norm(output)\n",
        "        output = output.cpu().detach().numpy()\n",
        "        \n",
        "        return np.hstack([np.mean(output, axis=0), np.max(output, axis=0), output[0,:,:], penul[0,:,:]])\n",
        "    \n",
        "    def encode(self, src):\n",
        "        batch_size = src.shape[1]\n",
        "        if batch_size <= 100:\n",
        "            return self._encode(src)\n",
        "        else: # Batch is too large to load\n",
        "            i = 0\n",
        "            while i < batch_size:\n",
        "                if o == 0:\n",
        "                    out = self._encode(src[:, i:i+100])\n",
        "                else:\n",
        "                    out = np.concatenate([out, self._encode(src[:, i:i+100])], axis=0)\n",
        "                i += 100\n",
        "            return out\n",
        "\n",
        "def evaluate(model, test_loader, vocab):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    for b, sm in enumerate(test_loader):\n",
        "        sm = torch.t(sm.cuda())\n",
        "        with torch.no_grad():\n",
        "            output = model(sm)\n",
        "        loss = F.nll_loss(output.view(-1, len(vocab)),\n",
        "                               sm.contiguous().view(-1),\n",
        "                               ignore_index=PAD)\n",
        "        total_loss += loss.item()\n",
        "    return total_loss / len(test_loader)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RiKmEPug8cz1",
        "outputId": "94fed900-12f4-40a4-b630-b0c9ec0d420c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "45\n",
            "Train size: 1712297\n",
            "Test size: 10000\n"
          ]
        }
      ],
      "source": [
        "vocab = Vocab.load_vocab('/content/drive/MyDrive/data/vocab24.pkl')\n",
        "df = pd.read_csv('/content/drive/MyDrive/data/chembl_24_dropped.csv')\n",
        "print(len(vocab))\n",
        "dataset = MyDataset(df['canonical_smiles'].values, vocab)\n",
        "test_size = 10000\n",
        "train, test = torch.utils.data.random_split(dataset, [len(dataset)-test_size, test_size])\n",
        "train_loader = DataLoader(train, batch_size= 8 , shuffle=True, num_workers=2)\n",
        "test_loader = DataLoader(test, batch_size=8, shuffle=False, num_workers=2)\n",
        "print('Train size:', len(train))\n",
        "print('Test size:', len(test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "ixEFimTaaVkt"
      },
      "outputs": [],
      "source": [
        "model = SandwichSmTrfm(len(vocab), 256, len(vocab), 4, 1, False, True).cuda()\n",
        "n_epochs=15\n",
        "criterion = nn.NLLLoss(ignore_index=PAD)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5, weight_decay=1e-5)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=(len(train_loader) * n_epochs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "ZM-pbHb55eIe",
        "outputId": "c4b7e323-f7d4-4c4c-8465-da5210ff05d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train:   0%|          | 292/214038 [00:14<2:26:48, 24.27it/s, loss=2.648283962910493]"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-61-5b738e9da9a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m             }, pathname)\n\u001b[1;32m     39\u001b[0m         \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/cuda/amp/grad_scaler.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, optimizer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    336\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"found_inf_per_device\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"No inf checks were recorded for this optimizer.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 338\u001b[0;31m         \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_opt_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m         \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"stage\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOptState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSTEPPED\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/cuda/amp/grad_scaler.py\u001b[0m in \u001b[0;36m_maybe_opt_step\u001b[0;34m(self, optimizer, optimizer_state, *args, **kwargs)\u001b[0m\n\u001b[1;32m    283\u001b[0m         \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"found_inf_per_device\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m             \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mretval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m                 \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m                 \u001b[0mwrapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0;31m# Note that the returned function here is no longer a bound method,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    151\u001b[0m                    \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weight_decay'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m                    \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m                    maximize=group['maximize'])\n\u001b[0m\u001b[1;32m    154\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/_functional.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m         \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m             \u001b[0;31m# Maintains the maximum of all 2nd moment running avg. till now\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import pdb\n",
        "from tqdm import tqdm\n",
        "\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "best_loss = 1e10\n",
        "\n",
        "for epoch in range(0,12):\n",
        "    batch_bar = tqdm(total=len(train_loader), dynamic_ncols=True, leave=False, position=0, desc='Train') \n",
        "    total_loss = 0.0\n",
        "    for i, sm in enumerate(train_loader):\n",
        "        sm = torch.t(sm.cuda())\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        with torch.cuda.amp.autocast():\n",
        "            output = model(sm)\n",
        "            loss = criterion(output.view(-1, len(vocab)),sm.contiguous().view(-1))\n",
        "        total_loss += float(loss)\n",
        "        batch_bar.set_postfix(\n",
        "                loss=f\"{float(total_loss / (i + 1))}\")\n",
        "      \n",
        "        if i > 0 and i % 5000 ==0:\n",
        "            val_loss = evaluate(model, test_loader, vocab)\n",
        "            print('Val {:3d}: iter {:5d} | loss {:.10f} | perplexity {:.10f}'.format(epoch, i, val_loss, math.exp(loss)))\n",
        "\n",
        "            if val_loss < best_loss:\n",
        "                pathname = '/content/drive/MyDrive/project_best.pth' \n",
        "                torch.save({'epoch': epoch, 'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'scheduler_state_dict': scheduler.state_dict(),\n",
        "                }, pathname)\n",
        "                best_loss = loss\n",
        "  \n",
        "            model.train()\n",
        "            pathname = '/content/drive/MyDrive/project.pth' \n",
        "            torch.save({'epoch': epoch, 'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'scheduler_state_dict': scheduler.state_dict(),\n",
        "            }, pathname)\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "        scheduler.step()\n",
        "        batch_bar.update()\n",
        "    batch_bar.close()\n",
        "    print(\"Epoch {}/{}: Train Loss {:.04f}\".format(\n",
        "          epoch + 1,\n",
        "          12,\n",
        "          float(total_loss / len(train_loader))))\n",
        "    torch.save({'epoch': epoch,\n",
        "          'model_state_dict': model.state_dict(),\n",
        "          'optimizer_state_dict': optimizer.state_dict(),\n",
        "          'scheduler_state_dict': scheduler.state_dict(),\n",
        "          }, 'drive/MyDrive/project.pth')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "Sandwich Transformer.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}