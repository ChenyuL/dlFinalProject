{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vGwDggQgayeQ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "import os\n",
        "import pickle\n",
        "from collections import defaultdict\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import gzip\n",
        "import shutil\n",
        "import spacy \n",
        "import pandas as pd \n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TIJ5HEbYad7W",
        "outputId": "4e59949e-088a-4f35-80d9-b53a34573e72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 57 kB 3.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 60 kB 7.2 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install kora -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x7vKDR48b-Mt"
      },
      "outputs": [],
      "source": [
        "import kora.install.rdkit\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import Draw, MolFromSmiles, MolToSmiles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7z9bH-luwORy",
        "outputId": "c2638a2b-284d-4017-faee-549ca263b0c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ybc2UQjib_77",
        "outputId": "add1260e-3f6c-43ee-c7a1-89fd399af257"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1dBDfrLzsluViEo50WrncEp56WUihj3GB/11785FinalProject\n",
            "/content/drive/.shortcut-targets-by-id/1dBDfrLzsluViEo50WrncEp56WUihj3GB/11785FinalProject\n"
          ]
        }
      ],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "!cp -r \"/content/drive/MyDrive/11785FinalProject\" /content/\n",
        "\n",
        "%cd /content/11785FinalProject\n",
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f9f0PLDzdJmF"
      },
      "outputs": [],
      "source": [
        "# !unzip -q /content/drive/MyDrive/Colab Notebooks/11785FinalProject/transformer_xl.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XS7YzAE6UgZX",
        "outputId": "c09be4b4-ebc7-4727-fa11-fa1d468b3853"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shell-init: error retrieving current directory: getcwd: cannot access parent directories: No such file or directory\n",
            " 0411smilesmodel_epoch0.pth\n",
            " bace.csv\n",
            " BBBP.csv\n",
            " chembl_24_chemreps.txt.gz\n",
            " chembl_24_dropped.csv\n",
            " chembl_30_chemreps.txt.gz\n",
            " ChemBL_Explore.ipynb\n",
            " dataset\n",
            "'Deep Learning Project Proposal.docx'\n",
            "'de novo Molecular Generation using SMILES Transformer.gdoc'\n",
            "'de novo Molecular Generation using SMILES Transformer.pdf'\n",
            " file.txt\n",
            " HIV.csv\n",
            " Load_baseline_model.ipynb\n",
            " __MACOSX\n",
            " Manuscript\n",
            " MITCourse.pdf\n",
            " notebooks\n",
            " PlotComparison.ipynb\n",
            " smilesmodel_epoch0.pth\n",
            " smilesmodel_epoch1.pth\n",
            " smilesmodel_epoch2.pth\n",
            " smilesmodel_epoch3.pth\n",
            " smilesmodel_epoch4.pth\n",
            " smilesmodel_epoch5.pth\n",
            " smilesmodel_epoch6.pth\n",
            " smilesmodel_epoch7.pth\n",
            " smilesmodel_epoch8.pth\n",
            " smilesmodel_epoch9.pth\n",
            " transformer_xl\n",
            " transformer_xl.zip\n",
            " trfm_12_23000.pkl\n",
            " vocab24.pkl\n",
            " vocab_chembl24.pkl\n",
            " vocab.pkl\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mUcTjuB0iKDv"
      },
      "outputs": [],
      "source": [
        "# reproducibility\n",
        "torch.manual_seed(314)\n",
        "np.random.seed(314)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGiLQlk4dhyf"
      },
      "source": [
        "# Smile Enumerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mVj_F5rDdlGR"
      },
      "outputs": [],
      "source": [
        "class Iterator(object):\n",
        "    \"\"\"Abstract base class for data iterators.\n",
        "    # Arguments\n",
        "        n: Integer, total number of samples in the dataset to loop over.\n",
        "        batch_size: Integer, size of a batch.\n",
        "        shuffle: Boolean, whether to shuffle the data between epochs.\n",
        "        seed: Random seeding for data shuffling.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, n, batch_size, shuffle, seed):\n",
        "        self.n = n\n",
        "        self.batch_size = batch_size\n",
        "        self.shuffle = shuffle\n",
        "        self.batch_index = 0\n",
        "        self.total_batches_seen = 0\n",
        "        self.index_generator = self._flow_index(n, batch_size, shuffle, seed)\n",
        "        if n < batch_size:\n",
        "            raise ValueError('Input data length is shorter than batch_size\\nAdjust batch_size')\n",
        "\n",
        "    def reset(self):\n",
        "        self.batch_index = 0\n",
        "\n",
        "    def _flow_index(self, n, batch_size=32, shuffle=False, seed=None):\n",
        "        # Ensure self.batch_index is 0.\n",
        "        self.reset()\n",
        "        while 1:\n",
        "            if seed is not None:\n",
        "                np.random.seed(seed + self.total_batches_seen)\n",
        "            if self.batch_index == 0:\n",
        "                index_array = np.arange(n)\n",
        "                if shuffle:\n",
        "                    index_array = np.random.permutation(n)\n",
        "\n",
        "            current_index = (self.batch_index * batch_size) % n\n",
        "            if n > current_index + batch_size:\n",
        "                current_batch_size = batch_size\n",
        "                self.batch_index += 1\n",
        "            else:\n",
        "                current_batch_size = n - current_index\n",
        "                self.batch_index = 0\n",
        "            self.total_batches_seen += 1\n",
        "            yield (index_array[current_index: current_index + current_batch_size],\n",
        "                   current_index, current_batch_size)\n",
        "\n",
        "    def __iter__(self):\n",
        "        # Needed if we want to do something like:\n",
        "        # for x, y in data_gen.flow(...):\n",
        "        return self\n",
        "\n",
        "    def __next__(self, *args, **kwargs):\n",
        "        return self.next(*args, **kwargs)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class SmilesIterator(Iterator):\n",
        "    \"\"\"Iterator yielding data from a SMILES array.\n",
        "    # Arguments\n",
        "        x: Numpy array of SMILES input data.\n",
        "        y: Numpy array of targets data.\n",
        "        smiles_data_generator: Instance of `SmilesEnumerator`\n",
        "            to use for random SMILES generation.\n",
        "        batch_size: Integer, size of a batch.\n",
        "        shuffle: Boolean, whether to shuffle the data between epochs.\n",
        "        seed: Random seed for data shuffling.\n",
        "        dtype: dtype to use for returned batch. Set to keras.backend.floatx if using Keras\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, x, y, smiles_data_generator,\n",
        "                 batch_size=32, shuffle=False, seed=None,\n",
        "                 dtype=np.float32\n",
        "                 ):\n",
        "        if y is not None and len(x) != len(y):\n",
        "            raise ValueError('X (images tensor) and y (labels) '\n",
        "                             'should have the same length. '\n",
        "                             'Found: X.shape = %s, y.shape = %s' %\n",
        "                             (np.asarray(x).shape, np.asarray(y).shape))\n",
        "\n",
        "        self.x = np.asarray(x)\n",
        "\n",
        "        if y is not None:\n",
        "            self.y = np.asarray(y)\n",
        "        else:\n",
        "            self.y = None\n",
        "        self.smiles_data_generator = smiles_data_generator\n",
        "        self.dtype = dtype\n",
        "        super(SmilesIterator, self).__init__(x.shape[0], batch_size, shuffle, seed)\n",
        "\n",
        "    def next(self):\n",
        "        \"\"\"For python 2.x.\n",
        "        # Returns\n",
        "            The next batch.\n",
        "        \"\"\"\n",
        "        # Keeps under lock only the mechanism which advances\n",
        "        # the indexing of each batch.\n",
        "        index_array, current_index, current_batch_size = next(self.index_generator)\n",
        "        # The transformation of images is not under thread lock\n",
        "        # so it can be done in parallel\n",
        "        batch_x = np.zeros(tuple([current_batch_size] + [ self.smiles_data_generator.pad, self.smiles_data_generator._charlen]), dtype=self.dtype)\n",
        "        for i, j in enumerate(index_array):\n",
        "            smiles = self.x[j:j+1]\n",
        "            x = self.smiles_data_generator.transform(smiles)\n",
        "            batch_x[i] = x\n",
        "\n",
        "        if self.y is None:\n",
        "            return batch_x\n",
        "        batch_y = self.y[index_array]\n",
        "        return batch_x, batch_y\n",
        "\n",
        "\n",
        "class SmilesEnumerator(object):\n",
        "    \"\"\"SMILES Enumerator, vectorizer and devectorizer\n",
        "    \n",
        "    #Arguments\n",
        "        charset: string containing the characters for the vectorization\n",
        "          can also be generated via the .fit() method\n",
        "        pad: Length of the vectorization\n",
        "        leftpad: Add spaces to the left of the SMILES\n",
        "        isomericSmiles: Generate SMILES containing information about stereogenic centers\n",
        "        enum: Enumerate the SMILES during transform\n",
        "        canonical: use canonical SMILES during transform (overrides enum)\n",
        "    \"\"\"\n",
        "    def __init__(self, charset = '@C)(=cOn1S2/H[N]\\\\', pad=120, leftpad=True, isomericSmiles=True, enum=True, canonical=False):\n",
        "        self._charset = None\n",
        "        self.charset = charset\n",
        "        self.pad = pad\n",
        "        self.leftpad = leftpad\n",
        "        self.isomericSmiles = isomericSmiles\n",
        "        self.enumerate = enum\n",
        "        self.canonical = canonical\n",
        "\n",
        "    @property\n",
        "    def charset(self):\n",
        "        return self._charset\n",
        "        \n",
        "    @charset.setter\n",
        "    def charset(self, charset):\n",
        "        self._charset = charset\n",
        "        self._charlen = len(charset)\n",
        "        self._char_to_int = dict((c,i) for i,c in enumerate(charset))\n",
        "        self._int_to_char = dict((i,c) for i,c in enumerate(charset))\n",
        "        \n",
        "    def fit(self, smiles, extra_chars=[], extra_pad = 5):\n",
        "        \"\"\"Performs extraction of the charset and length of a SMILES datasets and sets self.pad and self.charset\n",
        "        \n",
        "        #Arguments\n",
        "            smiles: Numpy array or Pandas series containing smiles as strings\n",
        "            extra_chars: List of extra chars to add to the charset (e.g. \"\\\\\\\\\" when \"/\" is present)\n",
        "            extra_pad: Extra padding to add before or after the SMILES vectorization\n",
        "        \"\"\"\n",
        "        charset = set(\"\".join(list(smiles)))\n",
        "        self.charset = \"\".join(charset.union(set(extra_chars)))\n",
        "        self.pad = max([len(smile) for smile in smiles]) + extra_pad\n",
        "        \n",
        "    def randomize_smiles(self, smiles):\n",
        "        \"\"\"Perform a randomization of a SMILES string\n",
        "        must be RDKit sanitizable\"\"\"\n",
        "        m = Chem.MolFromSmiles(smiles)\n",
        "        if m is None:\n",
        "          return None\n",
        "        ans = list(range(m.GetNumAtoms()))\n",
        "        np.random.shuffle(ans)\n",
        "        nm = Chem.RenumberAtoms(m,ans)\n",
        "        return Chem.MolToSmiles(nm, canonical=self.canonical, isomericSmiles=self.isomericSmiles)\n",
        "\n",
        "    def transform(self, smiles):\n",
        "        \"\"\"Perform an enumeration (randomization) and vectorization of a Numpy array of smiles strings\n",
        "        #Arguments\n",
        "            smiles: Numpy array or Pandas series containing smiles as strings\n",
        "        \"\"\"\n",
        "        one_hot =  np.zeros((smiles.shape[0], self.pad, self._charlen),dtype=np.int8)\n",
        "        \n",
        "        if self.leftpad:\n",
        "            for i,ss in enumerate(smiles):\n",
        "                if self.enumerate: ss = self.randomize_smiles(ss)\n",
        "                l = len(ss)\n",
        "                diff = self.pad - l\n",
        "                for j,c in enumerate(ss):\n",
        "                    one_hot[i,j+diff,self._char_to_int[c]] = 1\n",
        "            return one_hot\n",
        "        else:\n",
        "            for i,ss in enumerate(smiles):\n",
        "                if self.enumerate: ss = self.randomize_smiles(ss)\n",
        "                for j,c in enumerate(ss):\n",
        "                    one_hot[i,j,self._char_to_int[c]] = 1\n",
        "            return one_hot\n",
        "\n",
        "      \n",
        "    def reverse_transform(self, vect):\n",
        "        \"\"\" Performs a conversion of a vectorized SMILES to a smiles strings\n",
        "        charset must be the same as used for vectorization.\n",
        "        #Arguments\n",
        "            vect: Numpy array of vectorized SMILES.\n",
        "        \"\"\"       \n",
        "        smiles = []\n",
        "        for v in vect:\n",
        "            #mask v \n",
        "            v=v[v.sum(axis=1)==1]\n",
        "            #Find one hot encoded index with argmax, translate to char and join to string\n",
        "            smile = \"\".join(self._int_to_char[i] for i in v.argmax(axis=1))\n",
        "            smiles.append(smile)\n",
        "        return np.array(smiles)\n",
        "     \n",
        "# if __name__ == \"__main__\":\n",
        "#     smiles = np.array([ \"CCC(=O)O[C@@]1(CC[NH+](C[C@H]1CC=C)C)c2ccccc2\",\n",
        "#                         \"CCC[S@@](=O)c1ccc2c(c1)[nH]/c(=N/C(=O)OC)/[nH]2\"]*10\n",
        "#                         )\n",
        "#     #Test canonical SMILES vectorization\n",
        "#     sm_en = SmilesEnumerator(canonical=True, enum=False)\n",
        "#     sm_en.fit(smiles, extra_chars=[\"\\\\\"])\n",
        "#     v = sm_en.transform(smiles)\n",
        "#     transformed = sm_en.reverse_transform(v)\n",
        "#     if len(set(transformed)) > 2: print (\"Too many different canonical SMILES generated\")\n",
        "    \n",
        "#     #Test enumeration \n",
        "#     sm_en.canonical = False\n",
        "#     sm_en.enumerate = True\n",
        "#     v2 = sm_en.transform(smiles)\n",
        "#     transformed = sm_en.reverse_transform(v2)\n",
        "#     if len(set(transformed)) < 3: print (\"Too few enumerated SMILES generated\")\n",
        "\n",
        "#     #Reconstruction\n",
        "#     reconstructed = sm_en.reverse_transform(v[0:5])\n",
        "#     for i, smile in enumerate(reconstructed):\n",
        "#         if smile != smiles[i]:\n",
        "#             print (\"Error in reconstruction %s %s\".format(smile, smiles[i]))\n",
        "#             break\n",
        "    \n",
        "#     #test Pandas\n",
        "#     import pandas as pd\n",
        "#     df = pd.DataFrame(smiles)\n",
        "#     v = sm_en.transform(df[0])\n",
        "#     if v.shape != (20, 52, 18): print (\"Possible error in pandas use\")\n",
        "    \n",
        "#     #BUG, when batchsize > x.shape[0], then it only returns x.shape[0]!\n",
        "#     #Test batch generation\n",
        "#     sm_it = SmilesIterator(smiles, np.array([1,2]*10), sm_en, batch_size=10, shuffle=True)\n",
        "#     X, y = sm_it.next()\n",
        "#     if sum(y==1) - sum(y==2) > 1:\n",
        "#         print (\"Unbalanced generation of batches\")\n",
        "#     if len(X) != 10: print (\"Error in batchsize generation\" )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u0noJGmZ0NTa"
      },
      "source": [
        "# Data Loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hHrTe_ZscXwN"
      },
      "outputs": [],
      "source": [
        "class Randomizer(object):\n",
        "    def __init__(self):\n",
        "        self.enum = SmilesEnumerator()\n",
        "    \n",
        "    def __call__(self, smile):\n",
        "        random_smile = self.enum.randomize_smiles(smile)\n",
        "        if random_smile is None:\n",
        "            sm_spaced = split(smile)\n",
        "        else:\n",
        "            sm_spaced = split(random_smile)\n",
        "        sm_split = sm_spaced.split()\n",
        "\n",
        "        if len(sm_split) <= 218:\n",
        "            return sm_split\n",
        "        else:\n",
        "            return split(sm).split()\n",
        "\n",
        "    def random_transform(self, sm):\n",
        "        return self.enum.randomize_smiles(sm)\n",
        "\n",
        "# Copied Code\n",
        "class Seq2seqDataset(Dataset):\n",
        "\n",
        "    def __init__(self, smiles, vocab, seq_len=220, transform=Randomizer()):\n",
        "        self.smiles = smiles\n",
        "        self.vocab = vocab\n",
        "        self.seq_len = seq_len\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.smiles)\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        sm = self.smiles[item]\n",
        "        if sm is None:\n",
        "          return None\n",
        "        sm = self.transform(sm)\n",
        "        content = [self.vocab.stoi.get(token, self.vocab.unk_index) for token in sm]\n",
        "        X = [self.vocab.sos_index] + content + [self.vocab.eos_index]\n",
        "        padding = [self.vocab.pad_index]*(self.seq_len - len(X))\n",
        "        X.extend(padding)\n",
        "        return torch.tensor(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLUdaYePzGmF"
      },
      "source": [
        "Utils Library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ghzJaunWzhES"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import math\n",
        "import torch.nn as nn\n",
        "from rdkit import Chem\n",
        "from rdkit import rdBase\n",
        "rdBase.DisableLog('rdApp.*')\n",
        "\n",
        "def split(sm):\n",
        "    sm_couples = []\n",
        "    i = 0\n",
        "    while i < len(sm):\n",
        "        if i == len(sm) - 1:\n",
        "            sm_couples.append(sm[i])\n",
        "            i += 1\n",
        "        elif sm[i] == '%':\n",
        "            sm_couples.append(sm[i:i+3])\n",
        "            i += 3\n",
        "        elif sm[i:i+2] in ['Cl', 'Ca', 'Cu', 'Br', 'Be', 'Ba', 'Bi', 'Si', 'Se', 'Sr', 'Na', 'Ni', 'Rb', 'Ra', 'Xe', 'Li', 'Al', ' As', 'Ag', 'Au',\\\n",
        "                            'Mg', 'Mn', 'Te', 'Zn', 'si', 'se', 'te', 'He', 'Kr', 'Fe', '+2', '+3', '+4', '-2', '-3', '-4']:\n",
        "            sm_couples.append(sm[i:i+2])\n",
        "            i += 2\n",
        "        else:\n",
        "            sm_couples.append(sm[i])\n",
        "            i += 1\n",
        "    return ' '.join(sm_couples)\n",
        "# 活性化関数\n",
        "# class GELU(nn.Module):\n",
        "#     def forward(self, x):\n",
        "#         return 0.5 * x * (1 + torch.tanh(math.sqrt(2 / math.pi) * (x + 0.044715 * torch.pow(x, 3))))\n",
        "\n",
        "# 位置情報を考慮したFFN\n",
        "class PositionwiseFeedForward(nn.Module):\n",
        "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
        "        super(PositionwiseFeedForward, self).__init__()\n",
        "        self.w_1 = nn.Linear(d_model, d_ff)\n",
        "        self.w_2 = nn.Linear(d_ff, d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.activation = nn.GELU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.w_2(self.dropout(self.activation(self.w_1(x))))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oISuFNuA13OC"
      },
      "source": [
        "Build Vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rbcEQ3ro15D5"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "import pickle\n",
        "from collections import Counter\n",
        "\n",
        "\n",
        "class TorchVocab(object):\n",
        "    def __init__(self, counter, max_size=None, min_freq=1, specials=['<pad>', '<oov>'],\n",
        "                 vectors=None, unk_init=None, vectors_cache=None):\n",
        "        self.freqs = counter\n",
        "        counter = counter.copy()\n",
        "        min_freq = max(min_freq, 1)\n",
        "\n",
        "        self.itos = list(specials)\n",
        "        # special tokensの出現頻度はvocabulary作成の際にカウントされない\n",
        "        for tok in specials:\n",
        "            del counter[tok]\n",
        "\n",
        "        max_size = None if max_size is None else max_size + len(self.itos)\n",
        "\n",
        "        # まず頻度でソートし、次に文字順で並び替える\n",
        "        words_and_frequencies = sorted(counter.items(), key=lambda tup: tup[0])\n",
        "        words_and_frequencies.sort(key=lambda tup: tup[1], reverse=True)\n",
        "        \n",
        "        # 出現頻度がmin_freq未満のものはvocabに加えない\n",
        "        for word, freq in words_and_frequencies:\n",
        "            if freq < min_freq or len(self.itos) == max_size:\n",
        "                break\n",
        "            self.itos.append(word)\n",
        "\n",
        "        # dictのk,vをいれかえてstoiを作成する\n",
        "        self.stoi = {tok: i for i, tok in enumerate(self.itos)}\n",
        "\n",
        "        self.vectors = None\n",
        "        if vectors is not None:\n",
        "            self.load_vectors(vectors, unk_init=unk_init, cache=vectors_cache)\n",
        "        else:\n",
        "            assert unk_init is None and vectors_cache is None\n",
        "\n",
        "    def __eq__(self, other):\n",
        "        if self.freqs != other.freqs:\n",
        "            return False\n",
        "        if self.stoi != other.stoi:\n",
        "            return False\n",
        "        if self.itos != other.itos:\n",
        "            return False\n",
        "        if self.vectors != other.vectors:\n",
        "            return False\n",
        "        return True\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.itos)\n",
        "\n",
        "    def vocab_rerank(self):\n",
        "        self.stoi = {word: i for i, word in enumerate(self.itos)}\n",
        "\n",
        "    def extend(self, v, sort=False):\n",
        "        words = sorted(v.itos) if sort else v.itos\n",
        "        for w in words:\n",
        "            if w not in self.stoi:\n",
        "                self.itos.append(w)\n",
        "                self.stoi[w] = len(self.itos) - 1\n",
        "\n",
        "\n",
        "class Vocab(TorchVocab):\n",
        "    def __init__(self, counter, max_size=None, min_freq=1):\n",
        "        self.pad_index = 0\n",
        "        self.unk_index = 1\n",
        "        self.eos_index = 2\n",
        "        self.sos_index = 3\n",
        "        self.mask_index = 4\n",
        "        super().__init__(counter, specials=[\"<pad>\", \"<unk>\", \"<eos>\", \"<sos>\", \"<mask>\"], max_size=max_size, min_freq=min_freq)\n",
        "\n",
        "    # override用\n",
        "    def to_seq(self, sentece, seq_len, with_eos=False, with_sos=False) -> list:\n",
        "        pass\n",
        "\n",
        "    # override用\n",
        "    def from_seq(self, seq, join=False, with_pad=False):\n",
        "        pass\n",
        "\n",
        "    @staticmethod\n",
        "    def load_vocab(vocab_path: str) -> 'Vocab':\n",
        "        with open(vocab_path, \"rb\") as f:\n",
        "            return pickle.load(f)\n",
        "\n",
        "    def save_vocab(self, vocab_path):\n",
        "        with open(vocab_path, \"wb\") as f:\n",
        "            pickle.dump(self, f)\n",
        "\n",
        "\n",
        "# テキストファイルからvocabを作成する\n",
        "class WordVocab(Vocab):\n",
        "    def __init__(self, texts, max_size=None, min_freq=1):\n",
        "        print(\"Building Vocab\")\n",
        "        counter = Counter()\n",
        "        for line in texts:\n",
        "            if isinstance(line, list):\n",
        "                words = line\n",
        "            else:\n",
        "                words = line.replace(\"\\n\", \"\").replace(\"\\t\", \"\").split()\n",
        "\n",
        "            for word in words:\n",
        "                counter[word] += 1\n",
        "        super().__init__(counter, max_size=max_size, min_freq=min_freq)\n",
        "\n",
        "    def to_seq(self, sentence, seq_len=None, with_eos=False, with_sos=False, with_len=False):\n",
        "        if isinstance(sentence, str):\n",
        "            sentence = sentence.split()\n",
        "\n",
        "        seq = [self.stoi.get(word, self.unk_index) for word in sentence]\n",
        "\n",
        "        if with_eos:\n",
        "            seq += [self.eos_index]  # this would be index 1\n",
        "        if with_sos:\n",
        "            seq = [self.sos_index] + seq\n",
        "\n",
        "        origin_seq_len = len(seq)\n",
        "\n",
        "        if seq_len is None:\n",
        "            pass\n",
        "        elif len(seq) <= seq_len:\n",
        "            seq += [self.pad_index for _ in range(seq_len - len(seq))]\n",
        "        else:\n",
        "            seq = seq[:seq_len]\n",
        "\n",
        "        return (seq, origin_seq_len) if with_len else seq\n",
        "\n",
        "    def from_seq(self, seq, join=False, with_pad=False):\n",
        "        words = [self.itos[idx]\n",
        "                 if idx < len(self.itos)\n",
        "                 else \"<%d>\" % idx\n",
        "                 for idx in seq\n",
        "                 if not with_pad or idx != self.pad_index]\n",
        "\n",
        "        return \" \".join(words) if join else words\n",
        "\n",
        "    @staticmethod\n",
        "    def load_vocab(vocab_path: str) -> 'WordVocab':\n",
        "        with open(vocab_path, \"rb\") as f:\n",
        "            return pickle.load(f)\n",
        "\n",
        "\n",
        "# def main():\n",
        "#     parser = argparse.ArgumentParser(description='Build a vocabulary pickle')\n",
        "#     parser.add_argument('--corpus_path', '-c', type=str, default='data/chembl24_corpus.txt', help='path to th ecorpus')\n",
        "#     parser.add_argument('--out_path', '-o', type=str, default='data/vocab.pkl', help='output file')\n",
        "#     parser.add_argument('--min_freq', '-m', type=int, default=500, help='minimum frequency for vocabulary')\n",
        "#     parser.add_argument('--vocab_size', '-v', type=int, default=None, help='max vocabulary size')\n",
        "#     parser.add_argument('--encoding', '-e', type=str, default='utf-8', help='encoding of corpus')\n",
        "#     args = parser.parse_args()\n",
        "\n",
        "#     with open(args.corpus_path, \"r\", encoding=args.encoding) as f:\n",
        "#         vocab = WordVocab(f, max_size=args.vocab_size, min_freq=args.min_freq)\n",
        "\n",
        "#     print(\"VOCAB SIZE:\", len(vocab))\n",
        "#     vocab.save_vocab(args.out_path)\n",
        "\n",
        "#if __name__=='__main__':\n",
        "#    main()\n",
        "     \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jRm_a2-p3jnh",
        "outputId": "e2d86599-5b35-489a-874d-ab947353878e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "45\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['__class__',\n",
              " '__delattr__',\n",
              " '__dict__',\n",
              " '__dir__',\n",
              " '__doc__',\n",
              " '__eq__',\n",
              " '__format__',\n",
              " '__ge__',\n",
              " '__getattribute__',\n",
              " '__gt__',\n",
              " '__hash__',\n",
              " '__init__',\n",
              " '__init_subclass__',\n",
              " '__le__',\n",
              " '__len__',\n",
              " '__lt__',\n",
              " '__module__',\n",
              " '__ne__',\n",
              " '__new__',\n",
              " '__reduce__',\n",
              " '__reduce_ex__',\n",
              " '__repr__',\n",
              " '__setattr__',\n",
              " '__sizeof__',\n",
              " '__str__',\n",
              " '__subclasshook__',\n",
              " '__weakref__',\n",
              " 'eos_index',\n",
              " 'extend',\n",
              " 'freqs',\n",
              " 'from_seq',\n",
              " 'itos',\n",
              " 'load_vocab',\n",
              " 'mask_index',\n",
              " 'pad_index',\n",
              " 'save_vocab',\n",
              " 'sos_index',\n",
              " 'stoi',\n",
              " 'to_seq',\n",
              " 'unk_index',\n",
              " 'vectors',\n",
              " 'vocab_rerank']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "vocab = WordVocab.load_vocab('/content/drive/MyDrive/data/vocab24.pkl')\n",
        "print(len(vocab))\n",
        "dir(vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Tw7NWhFQVjB"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "from typing import Optional, Any, Union, Callable\n",
        "\n",
        "import torch\n",
        "from torch import Tensor\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class SandwichTransformer(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model = 512, nhead: int = 8, num_encoder_layers: int = 6,\n",
        "                 num_decoder_layers: int = 6, dim_feedforward: int = 2048, dropout: float = 0.1,\n",
        "                 sandwich_k = 2, sandwich_encoder = False, sandwich_decoder = False,\n",
        "                 activation: Union[str, Callable[[Tensor], Tensor]] = F.relu,\n",
        "                 custom_encoder: Optional[Any] = None, custom_decoder: Optional[Any] = None,\n",
        "                 layer_norm_eps: float = 1e-5, batch_first: bool = False, norm_first: bool = False,\n",
        "                 device=None, dtype=None) -> None:\n",
        "        factory_kwargs = {'device': device, 'dtype': dtype}\n",
        "        super(SandwichTransformer, self).__init__()\n",
        "\n",
        "        encoder_layer = TransformerEncoderLayer(d_model, nhead, dim_feedforward, dropout,\n",
        "                                                activation, layer_norm_eps, batch_first, norm_first,\n",
        "                                                **factory_kwargs)\n",
        "        encoder_norm = nn.LayerNorm(d_model, eps=layer_norm_eps, **factory_kwargs)\n",
        "        self.encoder = TransformerEncoder(encoder_layer, num_encoder_layers, encoder_norm, sandwich_k if sandwich_encoder else 0)\n",
        "\n",
        "        decoder_layer = TransformerDecoderLayer(d_model, nhead, dim_feedforward, dropout,\n",
        "                                                activation, layer_norm_eps, batch_first, norm_first,\n",
        "                                                **factory_kwargs)\n",
        "        decoder_norm = nn.LayerNorm(d_model, eps=layer_norm_eps, **factory_kwargs)\n",
        "        self.decoder = TransformerDecoder(decoder_layer, num_decoder_layers, decoder_norm, sandwich_k if sandwich_decoder else 0)\n",
        "\n",
        "        self._reset_parameters()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.nhead = nhead\n",
        "\n",
        "        self.batch_first = batch_first\n",
        "        # self.sandwich_k = sandwich_k\n",
        "        # self.sandwich_encoder = sandwich_encoder\n",
        "        # self.sandwich_decoder = sandwich_decoder\n",
        "\n",
        "    def forward(self, src: Tensor, tgt: Tensor, src_mask: Optional[Tensor] = None, tgt_mask: Optional[Tensor] = None,\n",
        "                memory_mask: Optional[Tensor] = None, src_key_padding_mask: Optional[Tensor] = None,\n",
        "                tgt_key_padding_mask: Optional[Tensor] = None, memory_key_padding_mask: Optional[Tensor] = None) -> Tensor:\n",
        "\n",
        "        is_batched = src.dim() == 3\n",
        "        if not self.batch_first and src.size(1) != tgt.size(1) and is_batched:\n",
        "            raise RuntimeError(\"the batch number of src and tgt must be equal\")\n",
        "        elif self.batch_first and src.size(0) != tgt.size(0) and is_batched:\n",
        "            raise RuntimeError(\"the batch number of src and tgt must be equal\")\n",
        "\n",
        "        if src.size(-1) != self.d_model or tgt.size(-1) != self.d_model:\n",
        "            raise RuntimeError(\"the feature number of src and tgt must be equal to d_model\")\n",
        "\n",
        "        memory = self.encoder(src, mask=src_mask, src_key_padding_mask=src_key_padding_mask, )\n",
        "        output = self.decoder(tgt, memory, tgt_mask=tgt_mask, memory_mask=memory_mask,\n",
        "                              tgt_key_padding_mask=tgt_key_padding_mask,\n",
        "                              memory_key_padding_mask=memory_key_padding_mask)\n",
        "        return output\n",
        "\n",
        "\n",
        "    def generate_square_subsequent_mask(sz: int) -> Tensor:\n",
        "        return torch.triu(torch.full((sz, sz), float('-inf')), diagonal=1)\n",
        "\n",
        "\n",
        "    def _reset_parameters(self):\n",
        "\n",
        "        for p in self.parameters():\n",
        "            if p.dim() > 1:\n",
        "                nn.init.xavier_uniform_(p)\n",
        "\n",
        "class TransformerEncoder(nn.Module):\n",
        "    _constants_ = ['norm']\n",
        "\n",
        "    def __init__(self, encoder_layer, num_layers, norm=None, sandwich_k=0):\n",
        "        super(TransformerEncoder, self).__init__()\n",
        "        self.layers = _get_clones(encoder_layer, num_layers+sandwich_k)\n",
        "        self.num_layers = num_layers+sandwich_k\n",
        "        self.norm = norm\n",
        "        self.sandwich_k = sandwich_k\n",
        "\n",
        "    def forward(self, src: Tensor, mask: Optional[Tensor] = None, src_key_padding_mask: Optional[Tensor] = None) -> Tensor:\n",
        "        output = src\n",
        "\n",
        "        for i, mod in enumerate(self.layers):\n",
        "            if i < self.sandwich_k:\n",
        "                output = mod(output, src_mask=mask, src_key_padding_mask=src_key_padding_mask, layer_type=1)\n",
        "            elif i >= self.num_layers - self.sandwich_k:\n",
        "                output = mod(output, src_mask=mask, src_key_padding_mask=src_key_padding_mask, layer_type=2)\n",
        "            else:\n",
        "                output = mod(output, src_mask=mask, src_key_padding_mask=src_key_padding_mask, layer_type=0)\n",
        "\n",
        "        if self.norm is not None:\n",
        "            output = self.norm(output)\n",
        "\n",
        "        return output\n",
        "\n",
        "class TransformerDecoder(nn.Module):\n",
        "    _constants_ = ['norm']\n",
        "\n",
        "    def __init__(self, decoder_layer, num_layers, norm=None, sandwich_k=0):\n",
        "        super(TransformerDecoder, self).__init__()\n",
        "        self.layers = _get_clones(decoder_layer, num_layers+sandwich_k)\n",
        "        self.num_layers = num_layers+sandwich_k\n",
        "        self.norm = norm\n",
        "        self.sandwich_k = sandwich_k\n",
        "\n",
        "    def forward(self, tgt: Tensor, memory: Tensor, tgt_mask: Optional[Tensor] = None,\n",
        "                memory_mask: Optional[Tensor] = None, tgt_key_padding_mask: Optional[Tensor] = None,\n",
        "                memory_key_padding_mask: Optional[Tensor] = None) -> Tensor:\n",
        "        output = tgt\n",
        "\n",
        "        for i, mod in enumerate(self.layers):\n",
        "            if i < self.sandwich_k:\n",
        "                output = mod(output, memory, tgt_mask=tgt_mask,\n",
        "                      memory_mask=memory_mask,\n",
        "                      tgt_key_padding_mask=tgt_key_padding_mask,\n",
        "                      memory_key_padding_mask=memory_key_padding_mask, layer_type=1)\n",
        "            elif i >= self.num_layers - self.sandwich_k:\n",
        "                output = mod(output, memory, tgt_mask=tgt_mask,\n",
        "                      memory_mask=memory_mask,\n",
        "                      tgt_key_padding_mask=tgt_key_padding_mask,\n",
        "                      memory_key_padding_mask=memory_key_padding_mask, layer_type=2)\n",
        "            else:\n",
        "                output = mod(output, memory, tgt_mask=tgt_mask,\n",
        "                      memory_mask=memory_mask,\n",
        "                      tgt_key_padding_mask=tgt_key_padding_mask,\n",
        "                      memory_key_padding_mask=memory_key_padding_mask, layer_type=0)\n",
        "            \n",
        "\n",
        "        if self.norm is not None:\n",
        "            output = self.norm(output)\n",
        "\n",
        "        return output\n",
        "\n",
        "\n",
        "class TransformerEncoderLayer(nn.Module):\n",
        "    _constants_ = ['batch_first', 'norm_first']\n",
        "\n",
        "    # layer_type = 0 means regular layer, 1 means only self-attention, 2 means only feedsforward\n",
        "    def __init__(self, d_model: int, nhead: int, dim_feedforward: int = 2048, dropout: float = 0.1,\n",
        "                 activation: Union[str, Callable[[Tensor], Tensor]] = F.relu,\n",
        "                 layer_norm_eps: float = 1e-5, batch_first: bool = False, norm_first: bool = False,\n",
        "                 device=None, dtype=None) -> None:\n",
        "        factory_kwargs = {'device': device, 'dtype': dtype}\n",
        "        super(TransformerEncoderLayer, self).__init__()\n",
        "        self.self_attn = nn.MultiheadAttention(d_model, nhead, dropout=dropout, batch_first=batch_first,\n",
        "                                            **factory_kwargs)\n",
        "        # Implementation of Feedforward model\n",
        "        self.linear1 = nn.Linear(d_model, dim_feedforward, **factory_kwargs)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.linear2 = nn.Linear(dim_feedforward, d_model, **factory_kwargs)\n",
        "\n",
        "        self.norm_first = norm_first\n",
        "        self.norm1 = nn.LayerNorm(d_model, eps=layer_norm_eps, **factory_kwargs)\n",
        "        self.norm2 = nn.LayerNorm(d_model, eps=layer_norm_eps, **factory_kwargs)\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "\n",
        "        # Legacy string support for activation function.\n",
        "        if isinstance(activation, str):\n",
        "            self.activation = _get_activation_fn(activation)\n",
        "        else:\n",
        "            self.activation = activation\n",
        "\n",
        "    def _setstate_(self, state):\n",
        "        if 'activation' not in state:\n",
        "            state['activation'] = F.relu\n",
        "        super(TransformerEncoderLayer, self)._setstate_(state)\n",
        "\n",
        "    def forward(self, src: Tensor, src_mask: Optional[Tensor] = None, src_key_padding_mask: Optional[Tensor] = None\\\n",
        "                , layer_type=0) -> Tensor:\n",
        "        x = src\n",
        "        if self.norm_first:\n",
        "            if layer_type == 0:\n",
        "                x = x + self._sa_block(self.norm1(x), src_mask, src_key_padding_mask)\n",
        "                x = x + self._ff_block(self.norm2(x))\n",
        "            elif layer_type == 1:\n",
        "                x = x + self._sa_block(self.norm1(x), src_mask, src_key_padding_mask)\n",
        "            else:\n",
        "                x = x + self._ff_block(self.norm2(x))\n",
        "        else:\n",
        "            if layer_type == 0:\n",
        "                x = self.norm1(x + self._sa_block(x, src_mask, src_key_padding_mask))\n",
        "                x = self.norm2(x + self._ff_block(x))\n",
        "            elif layer_type == 1:\n",
        "                x = self.norm1(x + self._sa_block(x, src_mask, src_key_padding_mask))\n",
        "            else:\n",
        "                x = self.norm2(x + self._ff_block(x))\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "    # self-attention block\n",
        "    def _sa_block(self, x: Tensor,\n",
        "                  attn_mask: Optional[Tensor], key_padding_mask: Optional[Tensor]) -> Tensor:\n",
        "        x = self.self_attn(x, x, x,\n",
        "                           attn_mask=attn_mask,\n",
        "                           key_padding_mask=key_padding_mask,\n",
        "                           need_weights=False)[0]\n",
        "        return self.dropout1(x)\n",
        "\n",
        "    # feed forward block\n",
        "    def _ff_block(self, x: Tensor) -> Tensor:\n",
        "        x = self.linear2(self.dropout(self.activation(self.linear1(x))))\n",
        "        return self.dropout2(x)\n",
        "\n",
        "\n",
        "\n",
        "class TransformerDecoderLayer(nn.Module):\n",
        "    _constants_ = ['batch_first', 'norm_first']\n",
        "\n",
        "    def __init__(self, d_model: int, nhead: int, dim_feedforward: int = 2048, dropout: float = 0.1,\n",
        "                 activation: Union[str, Callable[[Tensor], Tensor]] = F.relu,\n",
        "                 layer_norm_eps: float = 1e-5, batch_first: bool = False, norm_first: bool = False,\n",
        "                 device=None, dtype=None) -> None:\n",
        "        factory_kwargs = {'device': device, 'dtype': dtype}\n",
        "        super(TransformerDecoderLayer, self).__init__()\n",
        "        self.self_attn = nn.MultiheadAttention(d_model, nhead, dropout=dropout, batch_first=batch_first,\n",
        "                                            **factory_kwargs)\n",
        "        self.multihead_attn = nn.MultiheadAttention(d_model, nhead, dropout=dropout, batch_first=batch_first,\n",
        "                                                 **factory_kwargs)\n",
        "        # Implementation of Feedforward model\n",
        "        self.linear1 = nn.Linear(d_model, dim_feedforward, **factory_kwargs)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.linear2 = nn.Linear(dim_feedforward, d_model, **factory_kwargs)\n",
        "\n",
        "        self.norm_first = norm_first\n",
        "        self.norm1 = nn.LayerNorm(d_model, eps=layer_norm_eps, **factory_kwargs)\n",
        "        self.norm2 = nn.LayerNorm(d_model, eps=layer_norm_eps, **factory_kwargs)\n",
        "        self.norm3 = nn.LayerNorm(d_model, eps=layer_norm_eps, **factory_kwargs)\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "        self.dropout3 = nn.Dropout(dropout)\n",
        "\n",
        "        # Legacy string support for activation function.\n",
        "        if isinstance(activation, str):\n",
        "            self.activation = _get_activation_fn(activation)\n",
        "        else:\n",
        "            self.activation = activation\n",
        "\n",
        "    def _setstate_(self, state):\n",
        "        if 'activation' not in state:\n",
        "            state['activation'] = F.relu\n",
        "        super(TransformerDecoderLayer, self)._setstate_(state)\n",
        "\n",
        "    def forward(self, tgt: Tensor, memory: Tensor, tgt_mask: Optional[Tensor] = None, memory_mask: Optional[Tensor] = None,\n",
        "                tgt_key_padding_mask: Optional[Tensor] = None, memory_key_padding_mask: Optional[Tensor] = None\\\n",
        "                , layer_type=0) -> Tensor:\n",
        "        # see Fig. 1 of https://arxiv.org/pdf/2002.04745v1.pdf\n",
        "\n",
        "        x = tgt\n",
        "        if self.norm_first:\n",
        "            if layer_type == 0:\n",
        "                x = x + self._sa_block(self.norm1(x), tgt_mask, tgt_key_padding_mask)\n",
        "                x = x + self._mha_block(self.norm2(x), memory, memory_mask, memory_key_padding_mask)\n",
        "                x = x + self._ff_block(self.norm3(x))\n",
        "            elif layer_type == 1:\n",
        "                x = x + self._sa_block(self.norm1(x), tgt_mask, tgt_key_padding_mask)\n",
        "                x = x + self._mha_block(self.norm2(x), memory, memory_mask, memory_key_padding_mask)\n",
        "            else:\n",
        "                x = x + self._ff_block(self.norm3(x))\n",
        "        else:\n",
        "            if layer_type == 0:\n",
        "                x = self.norm1(x + self._sa_block(x, tgt_mask, tgt_key_padding_mask))\n",
        "                x = self.norm2(x + self._mha_block(x, memory, memory_mask, memory_key_padding_mask))\n",
        "                x = self.norm3(x + self._ff_block(x))\n",
        "            elif layer_type == 1:\n",
        "                x = self.norm1(x + self._sa_block(x, tgt_mask, tgt_key_padding_mask))\n",
        "                x = self.norm2(x + self._mha_block(x, memory, memory_mask, memory_key_padding_mask))\n",
        "            else:\n",
        "                x = self.norm3(x + self._ff_block(x))\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "    # self-attention block\n",
        "    def _sa_block(self, x: Tensor,\n",
        "                  attn_mask: Optional[Tensor], key_padding_mask: Optional[Tensor]) -> Tensor:\n",
        "        x = self.self_attn(x, x, x,\n",
        "                           attn_mask=attn_mask,\n",
        "                           key_padding_mask=key_padding_mask,\n",
        "                           need_weights=False)[0]\n",
        "        return self.dropout1(x)\n",
        "\n",
        "    # multihead attention block\n",
        "    def _mha_block(self, x: Tensor, mem: Tensor,\n",
        "                   attn_mask: Optional[Tensor], key_padding_mask: Optional[Tensor]) -> Tensor:\n",
        "        x = self.multihead_attn(x, mem, mem,\n",
        "                                attn_mask=attn_mask,\n",
        "                                key_padding_mask=key_padding_mask,\n",
        "                                need_weights=False)[0]\n",
        "        return self.dropout2(x)\n",
        "\n",
        "    # feed forward block\n",
        "    def _ff_block(self, x: Tensor) -> Tensor:\n",
        "        x = self.linear2(self.dropout(self.activation(self.linear1(x))))\n",
        "        return self.dropout3(x)\n",
        "\n",
        "\n",
        "\n",
        "def _get_clones(module, N):\n",
        "    return nn.ModuleList([copy.deepcopy(module) for i in range(N)])\n",
        "\n",
        "\n",
        "def _get_activation_fn(activation):\n",
        "    if activation == \"relu\":\n",
        "        return F.relu\n",
        "    elif activation == \"gelu\":\n",
        "        return F.gelu\n",
        "\n",
        "    raise RuntimeError(\"activation should be relu/gelu, not {}\".format(activation))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMQOb6WM1hUI"
      },
      "source": [
        "Pre-Trained Transformer Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ek__RieB1n_i",
        "outputId": "44617177-d7fb-4099-82b2-b962ef2ba87b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading dataset...\n",
            "Train size: 1712298\n",
            "Test size: 10000\n"
          ]
        }
      ],
      "source": [
        "import argparse\n",
        "import math\n",
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torch.autograd import Variable\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "\n",
        "#from build_vocab import WordVocab\n",
        "#from dataset import Seq2seqDataset\n",
        "\n",
        "PAD = 0\n",
        "UNK = 1\n",
        "EOS = 2\n",
        "SOS = 3\n",
        "MASK = 4\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    \"Implement the PE function. No batch support?\"\n",
        "    def __init__(self, d_model, dropout, max_len=5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "        \n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0., max_len).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0., d_model, 2) * -(math.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0)\n",
        "        self.register_buffer('pe', pe)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = x + Variable(self.pe[:, :x.size(1)], \n",
        "                         requires_grad=False)\n",
        "        return self.dropout(x)\n",
        "\n",
        "class TrfmSeq2seq(nn.Module):\n",
        "    def __init__(self, in_size, hidden_size, out_size, n_layers, sandwich_k, sandwich_encoder, sandwich_decoder):\n",
        "        super(TrfmSeq2seq, self).__init__()\n",
        "        self.in_size = in_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.embed = nn.Embedding(in_size, hidden_size)\n",
        "        self.pe = PositionalEncoding(hidden_size, 0.1)\n",
        "        self.sandwich_k = sandwich_k\n",
        "        self.sandwich_encoder = sandwich_encoder\n",
        "        self.sandwich_decoder = sandwich_decoder\n",
        "        self.trfm = SandwichTransformer(d_model=hidden_size, nhead=4, \n",
        "        num_encoder_layers=n_layers, num_decoder_layers = n_layers, dim_feedforward=hidden_size,\n",
        "        sandwich_k=sandwich_k, sandwich_encoder=sandwich_encoder, sandwich_decoder=sandwich_decoder,\n",
        "        dropout=0.4)\n",
        "        self.out = nn.Linear(hidden_size, out_size)\n",
        "\n",
        "    def forward(self, src):\n",
        "        # src: (T,B)\n",
        "        embedded = self.embed(src)  # (T,B,H)\n",
        "        embedded += self.pe(embedded) # (T,B,H)\n",
        "        hidden = self.trfm(embedded, embedded) # (T,B,H)\n",
        "        out = self.out(hidden) # (T,B,V)\n",
        "        out = F.log_softmax(out, dim=2) # (T,B,V)\n",
        "        return out # (T,B,V)\n",
        "\n",
        "    def _encode(self, src):\n",
        "        # src: (T,B)\n",
        "        embedded = self.embed(src)  # (T,B,H)\n",
        "        embedded = self.pe(embedded) # (T,B,H)\n",
        "        output = embedded\n",
        "        if self.sandwich_encoder:\n",
        "            for i in range(self.trfm.encoder.num_layers - 1):\n",
        "                if i < self.sandwich_k:\n",
        "                    output = self.trfm.encoder.layers[i](output, None, layer_type=1)  # (T,B,H)\n",
        "                elif i >= self.trfm.encoder.num_layers - self.sandwich_k:\n",
        "                    output = self.trfm.encoder.layers[i](output, None, layer_type=2)\n",
        "                else:\n",
        "                    output = self.trfm.encoder.layers[i](output, None, layer_type=0)\n",
        "            penul = output.cpu().detach().numpy()\n",
        "            output = self.trfm.encoder.layers[-1](output, None, layer_type=2)  # (T,B,H)\n",
        "        else:\n",
        "            for i in range(self.trfm.encoder.num_layers - 1):\n",
        "                output = self.trfm.encoder.layers[i](output, None, layer_type=0)  # (T,B,H)\n",
        "            penul = output.cpu().detach().numpy()\n",
        "            output = self.trfm.encoder.layers[-1](output, None, layer_type=0)  # (T,B,H)\n",
        "        if self.trfm.encoder.norm:\n",
        "            output = self.trfm.encoder.norm(output) # (T,B,H)\n",
        "        output = output.cpu().detach().numpy()\n",
        "        # mean, max, first*2\n",
        "        return np.hstack([np.mean(output, axis=0), np.max(output, axis=0), output[0,:,:], penul[0,:,:] ]) # (B,4H)\n",
        "    \n",
        "    def encode(self, src):\n",
        "        # src: (T,B)\n",
        "        batch_size = src.shape[1]\n",
        "        if batch_size<=100:\n",
        "            return self._encode(src)\n",
        "        else: # Batch is too large to load\n",
        "            print('There are {:d} molecules. It will take a little time.'.format(batch_size))\n",
        "            st,ed = 0,100\n",
        "            out = self._encode(src[:,st:ed]) # (B,4H)\n",
        "            while ed<batch_size:\n",
        "                st += 100\n",
        "                ed += 100\n",
        "                out = np.concatenate([out, self._encode(src[:,st:ed])], axis=0)\n",
        "            return out\n",
        "\n",
        "def evaluate(model, test_loader, vocab):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    for b, sm in enumerate(test_loader):\n",
        "        sm = torch.t(sm.cuda()) # (T,B)\n",
        "        with torch.no_grad():\n",
        "            output = model(sm) # (T,B,V)\n",
        "        loss = F.nll_loss(output.view(-1, len(vocab)),\n",
        "                               sm.contiguous().view(-1),\n",
        "                               ignore_index=PAD)\n",
        "        total_loss += loss.item()\n",
        "    return total_loss / len(test_loader)\n",
        "\n",
        "#args = parse_arguments()\n",
        "# assert torch.cuda.is_available()\n",
        "\n",
        "print('Loading dataset...')\n",
        "vocab = WordVocab.load_vocab('/content/drive/MyDrive/data/vocab24.pkl') #args.vocab)\n",
        "df = pd.read_csv('/content/drive/MyDrive/data/chembl_24_dropped.csv')\n",
        "dataset = Seq2seqDataset(df['canonical_smiles'].values, vocab)\n",
        "test_size = 10000\n",
        "train, test = torch.utils.data.random_split(dataset, [len(dataset)-test_size, test_size])\n",
        "train_loader = DataLoader(train, batch_size= 8 , shuffle=True, num_workers=2)   #args.batch_size:8   args.n_worker:16\n",
        "test_loader = DataLoader(test, batch_size=8, shuffle=False, num_workers=2)\n",
        "print('Train size:', len(train))\n",
        "print('Test size:', len(test))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uSiNANXce6f4"
      },
      "outputs": [],
      "source": [
        "class baseline(nn.Module):\n",
        "    def __init__(self, in_size, hidden_size, out_size, n_layers):\n",
        "        super(baseline, self).__init__()\n",
        "        self.in_size = in_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.embed = nn.Embedding(in_size, hidden_size)\n",
        "        self.pe = PositionalEncoding(hidden_size, 0.1)\n",
        "        \n",
        "        self.trfm = nn.Transformer(d_model=hidden_size, nhead=4, \n",
        "                num_encoder_layers=n_layers, num_decoder_layers = n_layers, dim_feedforward=hidden_size)\n",
        "        self.out = nn.Linear(hidden_size, out_size)\n",
        "\n",
        "    def forward(self, src):\n",
        "        # src: (T,B)\n",
        "        embedded = self.embed(src)  # (T,B,H)\n",
        "        embedded += self.pe(embedded) # (T,B,H)\n",
        "        hidden = self.trfm(embedded, embedded) # (T,B,H)\n",
        "        out = self.out(hidden) # (T,B,V)\n",
        "        out = F.log_softmax(out, dim=2) # (T,B,V)\n",
        "        return out # (T,B,V)\n",
        "\n",
        "    def _encode(self, src):\n",
        "        # src: (T,B)\n",
        "        embedded = self.embed(src)  # (T,B,H)\n",
        "        embedded = self.pe(embedded) # (T,B,H)\n",
        "        output = embedded\n",
        "        # if self.sandwich_encoder:\n",
        "        #     for i in range(self.trfm.encoder.num_layers - 1):\n",
        "        #         if i < self.sandwich_k:\n",
        "        #             output = self.trfm.encoder.layers[i](output, None, layer_type=1)  # (T,B,H)\n",
        "        #         elif i >= self.trfm.encoder.num_layers - self.sandwich_k:\n",
        "        #             output = self.trfm.encoder.layers[i](output, None, layer_type=2)\n",
        "        #         else:\n",
        "        #             output = self.trfm.encoder.layers[i](output, None, layer_type=0)\n",
        "        #     penul = output.cpu().detach().numpy()\n",
        "        #     output = self.trfm.encoder.layers[-1](output, None, layer_type=2)  # (T,B,H)\n",
        "        # else:\n",
        "        #     for i in range(self.trfm.encoder.num_layers - 1):\n",
        "        #         output = self.trfm.encoder.layers[i](output, None)  # (T,B,H)\n",
        "        #     penul = output.cpu().detach().numpy()\n",
        "        #     output = self.trfm.encoder.layers[-1](output, None)  # (T,B,H)\n",
        "\n",
        "        for i in range(self.trfm.encoder.num_layers - 1):\n",
        "            output = self.trfm.encoder.layers[i](output, None)  # (T,B,H)\n",
        "            # print(f'{i} finished')\n",
        "        penul = output.cpu().detach().numpy()\n",
        "        output = self.trfm.encoder.layers[-1](output, None)  # (T,B,H)\n",
        "\n",
        "        if self.trfm.encoder.norm:\n",
        "            output = self.trfm.encoder.norm(output) # (T,B,H)\n",
        "        output = output.cpu().detach().numpy()\n",
        "        # mean, max, first*2\n",
        "        return np.hstack([np.mean(output, axis=0), np.max(output, axis=0), output[0,:,:], penul[0,:,:] ]) # (B,4H)\n",
        "    \n",
        "    def encode(self, src):\n",
        "        # src: (T,B)\n",
        "        batch_size = src.shape[1]\n",
        "        if batch_size<=100:\n",
        "            return self._encode(src)\n",
        "        else: # Batch is too large to load\n",
        "            print('There are {:d} molecules. It will take a little time.'.format(batch_size))\n",
        "            st,ed = 0,100\n",
        "            out = self._encode(src[:,st:ed]) # (B,4H)\n",
        "            # print(batch_size)\n",
        "            while ed<batch_size:\n",
        "                st += 100\n",
        "                ed += 100\n",
        "                # if ed % 1000 == 0:\n",
        "                #     print(ed)\n",
        "                out = np.concatenate([out, self._encode(src[:,st:ed])], axis=0)\n",
        "            return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RiKmEPug8cz1"
      },
      "outputs": [],
      "source": [
        "# print('Train size:', len(train))\n",
        "# print('Test size:', len(test))\n",
        "# print(len(vocab))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FQtpS_k2e_sh"
      },
      "outputs": [],
      "source": [
        "model = TrfmSeq2seq(45, 256, 45, 4, 3, False,True )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MGv7Wo3oe_ze",
        "outputId": "8a4cae8c-5735-4e43-bcb6-723f886da04a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "trfm = baseline(45, 256, 45, 4)\n",
        "trfm.load_state_dict(torch.load('/content/drive/MyDrive/trfm_12_23000.pkl'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r5j6qooeg7_u"
      },
      "outputs": [],
      "source": [
        "for i,encoderlayer in enumerate(trfm.trfm.encoder.layers):\n",
        "  model.trfm.encoder.layers[i].linear1.weight = encoderlayer.linear1.weight\n",
        "  model.trfm.encoder.layers[i].linear2.weight = encoderlayer.linear2.weight\n",
        "  model.trfm.encoder.layers[i].norm1.weight = encoderlayer.norm1.weight\n",
        "  model.trfm.encoder.layers[i].norm2.weight = encoderlayer.norm2.weight\n",
        "  model.trfm.encoder.layers[i].linear1.bias = encoderlayer.linear1.bias\n",
        "  model.trfm.encoder.layers[i].linear2.bias = encoderlayer.linear2.bias\n",
        "  model.trfm.encoder.layers[i].norm1.bias = encoderlayer.norm1.bias\n",
        "  model.trfm.encoder.layers[i].norm2.bias = encoderlayer.norm2.bias\n",
        "  model.trfm.encoder.layers[i].self_attn.in_proj_bias = encoderlayer.self_attn.in_proj_bias\n",
        "  model.trfm.encoder.layers[i].self_attn.in_proj_weight = encoderlayer.self_attn.in_proj_weight\n",
        "\n",
        "  # if i >= 2:\n",
        "  #     model.trfm.encoder.layers[i+2].linear1.weight = encoderlayer.linear1.weight\n",
        "  #     model.trfm.encoder.layers[i+2].linear2.weight = encoderlayer.linear2.weight\n",
        "  #     model.trfm.encoder.layers[i+2].norm1.weight = encoderlayer.norm1.weight\n",
        "  #     model.trfm.encoder.layers[i+2].norm2.weight = encoderlayer.norm2.weight\n",
        "  #     model.trfm.encoder.layers[i+2].linear1.bias = encoderlayer.linear1.bias\n",
        "  #     model.trfm.encoder.layers[i+2].linear2.bias = encoderlayer.linear2.bias\n",
        "  #     model.trfm.encoder.layers[i+2].norm1.bias = encoderlayer.norm1.bias\n",
        "  #     model.trfm.encoder.layers[i+2].norm2.bias = encoderlayer.norm2.bias\n",
        "  #     model.trfm.encoder.layers[i+2].self_attn.in_proj_bias = encoderlayer.self_attn.in_proj_bias\n",
        "  #     model.trfm.encoder.layers[i+2].self_attn.in_proj_weight = encoderlayer.self_attn.in_proj_weight\n",
        "  \n",
        "for j,decoderlayer in enumerate(trfm.trfm.decoder.layers):\n",
        "  model.trfm.decoder.layers[j].linear1.weight = decoderlayer.linear1.weight\n",
        "  model.trfm.decoder.layers[j].linear2.weight = decoderlayer.linear2.weight\n",
        "  model.trfm.decoder.layers[j].norm1.weight = decoderlayer.norm1.weight\n",
        "  model.trfm.decoder.layers[j].norm2.weight = decoderlayer.norm2.weight\n",
        "  model.trfm.decoder.layers[j].norm3.weight = decoderlayer.norm3.weight\n",
        "  model.trfm.decoder.layers[j].linear1.bias = decoderlayer.linear1.bias\n",
        "  model.trfm.decoder.layers[j].linear2.bias = decoderlayer.linear2.bias\n",
        "  model.trfm.decoder.layers[j].norm1.bias = decoderlayer.norm1.bias\n",
        "  model.trfm.decoder.layers[j].norm2.bias = decoderlayer.norm2.bias\n",
        "  model.trfm.decoder.layers[j].norm3.bias = decoderlayer.norm3.bias\n",
        "  model.trfm.decoder.layers[j].self_attn.in_proj_bias = decoderlayer.self_attn.in_proj_bias\n",
        "  model.trfm.decoder.layers[j].self_attn.in_proj_weight = decoderlayer.self_attn.in_proj_weight\n",
        "  model.trfm.decoder.layers[j].multihead_attn.in_proj_bias = decoderlayer.multihead_attn.in_proj_bias\n",
        "  model.trfm.decoder.layers[j].multihead_attn.in_proj_weight = decoderlayer.multihead_attn.in_proj_weight\n",
        "  if j >= 1:\n",
        "    model.trfm.decoder.layers[j+3].linear1.weight = decoderlayer.linear1.weight\n",
        "    model.trfm.decoder.layers[j+3].linear2.weight = decoderlayer.linear2.weight\n",
        "    model.trfm.decoder.layers[j+3].norm1.weight = decoderlayer.norm1.weight\n",
        "    model.trfm.decoder.layers[j+3].norm2.weight = decoderlayer.norm2.weight\n",
        "    model.trfm.decoder.layers[j+3].norm3.weight = decoderlayer.norm3.weight\n",
        "    model.trfm.decoder.layers[j+3].linear1.bias = decoderlayer.linear1.bias\n",
        "    model.trfm.decoder.layers[j+3].linear2.bias = decoderlayer.linear2.bias\n",
        "    model.trfm.decoder.layers[j+3].norm1.bias = decoderlayer.norm1.bias\n",
        "    model.trfm.decoder.layers[j+3].norm2.bias = decoderlayer.norm2.bias\n",
        "    model.trfm.decoder.layers[j+3].norm3.bias = decoderlayer.norm3.bias\n",
        "    model.trfm.decoder.layers[j+3].self_attn.in_proj_bias = decoderlayer.self_attn.in_proj_bias\n",
        "    model.trfm.decoder.layers[j+3].self_attn.in_proj_weight = decoderlayer.self_attn.in_proj_weight\n",
        "    model.trfm.decoder.layers[j+3].multihead_attn.in_proj_bias = decoderlayer.multihead_attn.in_proj_bias\n",
        "    model.trfm.decoder.layers[j+3].multihead_attn.in_proj_weight = decoderlayer.multihead_attn.in_proj_weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ixEFimTaaVkt"
      },
      "outputs": [],
      "source": [
        "model = model.cuda()\n",
        "n_epochs=15\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5, weight_decay=1e-5)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=(len(train_loader) * n_epochs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SvnyxMhi54hh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 533
        },
        "outputId": "755e7947-aa03-43cc-dc7f-a4a344a076af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adam (\n",
            "Parameter Group 0\n",
            "    amsgrad: False\n",
            "    betas: (0.9, 0.999)\n",
            "    eps: 1e-08\n",
            "    initial_lr: 1e-05\n",
            "    lr: 9.999486540617892e-06\n",
            "    weight_decay: 1e-05\n",
            ")\n",
            "[{'lr': 5.522642316338376e-06, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 1e-05, 'amsgrad': False, 'initial_lr': 1e-05, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138]}]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-71-85a6f8e07ddf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'optimizer_state_dict'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'param_groups'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'optimizer_state_dict'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'scheduler_state_dict'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict)\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0msaved_lens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'params'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msaved_groups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_len\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0ms_len\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms_len\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam_lens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaved_lens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m             raise ValueError(\"loaded state dict contains a parameter group \"\n\u001b[0m\u001b[1;32m    147\u001b[0m                              \"that doesn't match the size of optimizer's group\")\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: loaded state dict contains a parameter group that doesn't match the size of optimizer's group"
          ]
        }
      ],
      "source": [
        "# from torch.optim.optimizer import Optimizer\n",
        "checkpoint = torch.load('/content/drive/MyDrive/project_epoch7.pth')\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "# print(model.load_state_dict(checkpoint['model_state_dict']))\n",
        "# print(checkpoint['model_state_dict'])\n",
        "\n",
        "# print(optimizer)\n",
        "# print(checkpoint['optimizer_state_dict']['param_groups'])\n",
        "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "scheduler.load_state_dict(checkpoint['scheduler_state_dict'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H-WKsKR4ThIc"
      },
      "outputs": [],
      "source": [
        "# print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZM-pbHb55eIe",
        "outputId": "c6b1fbf0-b3f0-4547-9d27-e549f6e89630"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: 0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train:  47%|████▋     | 100000/214038 [1:14:49<1:27:28, 21.73it/s, loss=2.0606740786323778e-05]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val   0: iter 100000 | loss 0.0000170578 | perplexity 1.0000156749\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train:  93%|█████████▎| 200000/214038 [2:30:43<10:17, 22.74it/s, loss=2.0967300356839834e-05]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val   0: iter 200000 | loss 0.0000390091 | perplexity 1.0000158437\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train:  47%|████▋     | 100000/214038 [1:14:51<1:25:20, 22.27it/s, loss=2.209032394104693e-05]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val   1: iter 100000 | loss 0.0000174531 | perplexity 1.0000146162\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train:  93%|█████████▎| 200000/214038 [2:29:21<10:35, 22.09it/s, loss=2.1975820983642728e-05]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val   1: iter 200000 | loss 0.0000169816 | perplexity 1.0000132268\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: 2\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train:  47%|████▋     | 100000/214038 [1:14:50<1:26:38, 21.94it/s, loss=2.239154203452171e-05]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val   2: iter 100000 | loss 0.0000165117 | perplexity 1.0000136749\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train:  93%|█████████▎| 200000/214038 [2:29:56<10:27, 22.39it/s, loss=2.15877201926111e-05]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val   2: iter 200000 | loss 0.0000433547 | perplexity 1.0000101234\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: 3\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train:  47%|████▋     | 100000/214038 [1:14:35<1:23:45, 22.69it/s, loss=2.0809700131596718e-05]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val   3: iter 100000 | loss 0.0000165958 | perplexity 1.0000139726\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train:  93%|█████████▎| 200000/214038 [2:29:40<10:22, 22.57it/s, loss=2.0771725628322394e-05]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val   3: iter 200000 | loss 0.0000165905 | perplexity 1.0000171438\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: 4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train:  47%|████▋     | 100000/214038 [1:17:03<1:29:12, 21.31it/s, loss=2.025160895979268e-05]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val   4: iter 100000 | loss 0.0000174197 | perplexity 1.0000143769\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train:  93%|█████████▎| 200000/214038 [2:35:30<11:18, 20.70it/s, loss=1.972342876843063e-05] "
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val   4: iter 200000 | loss 0.0000383549 | perplexity 1.0000133856\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train:  47%|████▋     | 100000/214038 [1:18:57<1:28:52, 21.39it/s, loss=2.1641345322793105e-05]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   5: iter 100000 | loss 0.0000382563 | perplexity 1.0000304011\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train:  93%|█████████▎| 200000/214038 [2:36:24<10:46, 21.72it/s, loss=2.0690373187790542e-05]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   5: iter 200000 | loss 0.0000162749 | perplexity 1.0000147524\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train:  98%|█████████▊| 209174/214038 [2:43:42<03:41, 21.96it/s, loss=2.0721223014751293e-05]"
          ]
        }
      ],
      "source": [
        "import pdb\n",
        "from tqdm import tqdm\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "\n",
        "best_loss = None\n",
        "for epoch in range(12):\n",
        "  print(\"epoch:\",epoch)\n",
        "  batch_bar = tqdm(total=len(train_loader), dynamic_ncols=True, leave=False, position=0, desc='Train') \n",
        "  total_loss = 0.0\n",
        "  for b, sm in enumerate(train_loader):\n",
        "    # if sm is None\n",
        "    #   continue\n",
        "    sm = torch.t(sm.cuda()) # (T,B)\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    with torch.cuda.amp.autocast():\n",
        "      output = model(sm) # (T,B,V)\n",
        "      loss = F.nll_loss(output.view(-1, len(vocab)),sm.contiguous().view(-1), ignore_index=PAD)\n",
        "    total_loss += float(loss)\n",
        "    # print(float(loss))\n",
        "    batch_bar.set_postfix(\n",
        "            loss=f\"{float(total_loss / (b + 1))}\")\n",
        "    \n",
        "    if b>0 and b%100000 ==0:\n",
        "      val_loss = evaluate(model, test_loader, vocab)\n",
        "      print('Val {:3d}: iter {:5d} | loss {:.10f} | perplexity {:.10f}'.format(epoch, b, val_loss, math.exp(loss)))\n",
        "      if not best_loss or loss < best_loss:\n",
        "        # print(\"[!] saving model...\")\n",
        "        pathname = '/content/11785FinalProject/notebooks/project_best.pth' \n",
        "        torch.save({'epoch': epoch, 'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "        }, pathname)\n",
        "        best_loss = val_loss\n",
        "      pathname = '/content/11785FinalProject/notebooks/project.pth' \n",
        "      torch.save({'epoch': epoch, 'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "        'scheduler_state_dict': scheduler.state_dict(),\n",
        "        }, pathname)\n",
        "    \n",
        "    pathname = f'/content/11785FinalProject/notebooks/project_epoch{epoch}.pth' \n",
        "    torch.save({'epoch': epoch, 'model_state_dict': model.state_dict(),\n",
        "          'optimizer_state_dict': optimizer.state_dict(),\n",
        "          'scheduler_state_dict': scheduler.state_dict(),\n",
        "          }, pathname)\n",
        "  \n",
        "    scaler.scale(loss).backward()\n",
        "    scaler.step(optimizer)\n",
        "    scaler.update()\n",
        "    scheduler.step()\n",
        "    # scheduler.step()\n",
        "    batch_bar.update()\n",
        "  batch_bar.close()\n",
        "  # print(\"Epoch {}/{}: Train Loss {:.04f}\".format(\n",
        "  #       b + 1,\n",
        "  #       b,\n",
        "  #       float(total_loss / len(train_loader))))\n",
        "  # torch.save({'epoch': 5,\n",
        "  #       'model_state_dict': model.state_dict(),\n",
        "  #       'optimizer_state_dict': optimizer.state_dict(),\n",
        "  #       }, 'drive/MyDrive/project.pth')\n",
        "    #print(loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-O_5iBvlSdD3"
      },
      "outputs": [],
      "source": [
        "torch.save({\n",
        "        # 'epoch': 5,\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "        }, '/content/11785FinalProject/notebooks/project.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Ld5lyHluhPn"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('HIV.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8xAuE5O3ullB"
      },
      "outputs": [],
      "source": [
        "from sklearn.neural_network import MLPRegressor, MLPClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score, roc_auc_score, precision_recall_curve, auc\n",
        "def evaluate_long_smiles(X_train, X_test, y_train, y_test, n_repeats):\n",
        "    auc = np.empty(n_repeats)\n",
        "    for i in range(n_repeats):\n",
        "        clf = MLPClassifier(max_iter=1000)\n",
        "        clf.fit(X_train, y_train)\n",
        "        y_score = clf.predict_proba(X_test)\n",
        "        auc[i] = roc_auc_score(y_test, y_score[:,1])\n",
        "    ret = {}\n",
        "    ret['auc mean'] = np.mean(auc)\n",
        "    ret['auc std'] = np.mean(np.std(auc, axis=0))\n",
        "    return ret\n",
        "def evaluate_mlp_classification(X, y, rate, n_repeats):\n",
        "    auc = np.empty(n_repeats)\n",
        "    for i in range(n_repeats):\n",
        "        clf = MLPClassifier(max_iter=1000)\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1-rate, stratify=y)\n",
        "        clf.fit(X_train, y_train)\n",
        "        y_score = clf.predict_proba(X_test)\n",
        "        auc[i] = roc_auc_score(y_test, y_score[:,1])\n",
        "    ret = {}\n",
        "    ret['auc mean'] = np.mean(auc)\n",
        "    ret['auc std'] = np.mean(np.std(auc, axis=0))\n",
        "    return ret\n",
        "\n",
        "def get_inputs(sm):\n",
        "    seq_len = 220\n",
        "    sm = sm.split()\n",
        "    if len(sm)>218:\n",
        "        print('SMILES is too long ({:d})'.format(len(sm)))\n",
        "        sm = sm[:109]+sm[-109:]\n",
        "    ids = [vocab.stoi.get(token, unk_index) for token in sm]\n",
        "    ids = [sos_index] + ids + [eos_index]\n",
        "    seg = [1]*len(ids)\n",
        "    padding = [pad_index]*(seq_len - len(ids))\n",
        "    ids.extend(padding), seg.extend(padding)\n",
        "    return ids, seg\n",
        "\n",
        "def get_array(smiles):\n",
        "    x_id, x_seg = [], []\n",
        "    for sm in smiles:\n",
        "        a,b = get_inputs(sm)\n",
        "        x_id.append(a)\n",
        "        x_seg.append(b)\n",
        "    return torch.tensor(x_id), torch.tensor(x_seg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "IFVsPtMMuoP_",
        "outputId": "54ce9919-0ae3-4680-882e-cfc32ea4b53c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SMILES is too long (220)\n",
            "SMILES is too long (274)\n",
            "SMILES is too long (247)\n",
            "SMILES is too long (226)\n",
            "SMILES is too long (244)\n",
            "SMILES is too long (243)\n",
            "SMILES is too long (253)\n",
            "SMILES is too long (266)\n",
            "SMILES is too long (346)\n",
            "SMILES is too long (232)\n",
            "SMILES is too long (242)\n",
            "SMILES is too long (247)\n",
            "SMILES is too long (240)\n",
            "SMILES is too long (370)\n",
            "SMILES is too long (224)\n",
            "SMILES is too long (283)\n",
            "SMILES is too long (265)\n",
            "SMILES is too long (240)\n",
            "SMILES is too long (219)\n",
            "SMILES is too long (246)\n",
            "SMILES is too long (243)\n",
            "SMILES is too long (284)\n",
            "SMILES is too long (270)\n",
            "SMILES is too long (232)\n",
            "SMILES is too long (260)\n",
            "SMILES is too long (284)\n",
            "SMILES is too long (284)\n",
            "SMILES is too long (439)\n",
            "SMILES is too long (491)\n",
            "SMILES is too long (439)\n",
            "SMILES is too long (296)\n",
            "SMILES is too long (341)\n",
            "SMILES is too long (285)\n",
            "SMILES is too long (327)\n",
            "SMILES is too long (341)\n",
            "SMILES is too long (400)\n",
            "SMILES is too long (263)\n",
            "SMILES is too long (238)\n",
            "SMILES is too long (383)\n",
            "SMILES is too long (360)\n",
            "SMILES is too long (233)\n",
            "SMILES is too long (365)\n",
            "SMILES is too long (265)\n",
            "SMILES is too long (240)\n",
            "SMILES is too long (223)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:   0%|          | 126/214038 [00:20<2:49:40, 21.01it/s, loss=5.712149315931666]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 41127 molecules. It will take a little time.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-56989f5e354e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mx_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msm\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'smiles'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mxid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_split\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-28-52c6466ca0dd>\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, src)\u001b[0m\n\u001b[1;32m    104\u001b[0m                 \u001b[0mst\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0med\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mst\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0med\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-28-52c6466ca0dd>\u001b[0m in \u001b[0;36m_encode\u001b[0;34m(self, src)\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrfm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_layers\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrfm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (T,B,H)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m             \u001b[0mpenul\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrfm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (T,B,H)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-27-25bcf4479f4b>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, src_mask, src_key_padding_mask, layer_type)\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlayer_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sa_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_key_padding_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ff_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mlayer_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-27-25bcf4479f4b>\u001b[0m in \u001b[0;36m_sa_block\u001b[0;34m(self, x, attn_mask, key_padding_mask)\u001b[0m\n\u001b[1;32m    198\u001b[0m                            \u001b[0mattn_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattn_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m                            \u001b[0mkey_padding_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkey_padding_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m                            need_weights=False)[0]\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/activation.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask)\u001b[0m\n\u001b[1;32m   1008\u001b[0m                 \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m                 \u001b[0mkey_padding_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkey_padding_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneed_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mneed_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1010\u001b[0;31m                 attn_mask=attn_mask)\n\u001b[0m\u001b[1;32m   1011\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_first\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1012\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mattn_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_output_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mmulti_head_attention_forward\u001b[0;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v)\u001b[0m\n\u001b[1;32m   5099\u001b[0m     \u001b[0;31m# (deep breath) calculate attention and out projection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5100\u001b[0m     \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5101\u001b[0;31m     \u001b[0mattn_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_output_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_scaled_dot_product_attention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5102\u001b[0m     \u001b[0mattn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattn_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtgt_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbsz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membed_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5103\u001b[0m     \u001b[0mattn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_proj_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_proj_bias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36m_scaled_dot_product_attention\u001b[0;34m(q, k, v, attn_mask, dropout_p)\u001b[0m\n\u001b[1;32m   4849\u001b[0m         \u001b[0mattn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdropout_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4850\u001b[0m     \u001b[0;31m# (B, Nt, Ns) x (B, Ns, E) -> (B, Nt, E)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4851\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4852\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4853\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "pad_index = 0\n",
        "unk_index = 1\n",
        "eos_index = 2\n",
        "sos_index = 3\n",
        "mask_index = 4\n",
        "\n",
        "rates = 2**np.arange(7)/80\n",
        "x_split = [split(sm) for sm in df['smiles'].values]\n",
        "xid, _ = get_array(x_split)\n",
        "X = model.encode(torch.t(xid).cuda())\n",
        "print(X.shape)\n",
        "total = 0.0\n",
        "for rate in rates:\n",
        "  score_dic = evaluate_mlp_classification(X, df['HIV_active'].values, rate, 20)\n",
        "  total += score_dict\n",
        "  print(rate, score_dic)\n",
        "\n",
        "print(total / len(rates))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VqNQrBz11VEJ"
      },
      "outputs": [],
      "source": [
        "# del model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zcE133yZaGkc",
        "outputId": "3cf771a6-08bc-4566-ffec-1d4f5579df16"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# model1 = TrfmSeq2seq(52, 256, 52, 4).cuda()\n",
        "# checkpoint = torch.load('drive/MyDrive/project.pth')\n",
        "# model1.load_state_dict(checkpoint['model_state_dict'])\n",
        "# optimizer.load_state_dict(checkpoint['optimizer_state_dict'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_N1NBEnaxUp3",
        "outputId": "650d444b-20f2-496f-b3ad-63d046c267e3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# model1 = TrfmSeq2seq(45, 256, 45, 4).cpu()\n",
        "# model1.load_state_dict(torch.load('/content/drive/MyDrive/trfm_12_23000.pkl'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DLjazTyeyFot",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "outputId": "19305f76-9499-4e5b-8abc-855960e07394"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-7f6569f7e96a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m   batch_bar.set_postfix(\n\u001b[0;32m---> 13\u001b[0;31m             loss=f\"{float(total_loss / (i + 1))}\")\n\u001b[0m\u001b[1;32m     14\u001b[0m   \u001b[0mbatch_bar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mbatch_bar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'i' is not defined"
          ]
        }
      ],
      "source": [
        "# model eval\n",
        "model.eval()\n",
        "total_loss = 0\n",
        "for b, sm in enumerate(test_loader):\n",
        "  sm = torch.t(sm.cuda()) # (T,B)\n",
        "  with torch.no_grad():\n",
        "      output = model(sm) # (T,B,V)\n",
        "  loss = F.nll_loss(output.view(-1, len(vocab)),\n",
        "                          sm.contiguous().view(-1),\n",
        "                          ignore_index=PAD)\n",
        "  total_loss += loss.item()\n",
        "  batch_bar.set_postfix(\n",
        "            loss=f\"{float(total_loss / (i + 1))}\")\n",
        "  batch_bar.update()\n",
        "batch_bar.close()\n",
        "print(total_loss / len(test_loader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o1dgM1zOxI6A"
      },
      "outputs": [],
      "source": [
        "model1.eval()\n",
        "total_loss = 0\n",
        "batch_bar = tqdm(total=len(test_loader), dynamic_ncols=True, leave=False, position=0, desc='Validation') \n",
        "for b, sm in enumerate(test_loader):\n",
        "  sm = torch.t(sm) # (T,B)\n",
        "  with torch.no_grad():\n",
        "      output = model1(sm) # (T,B,V)\n",
        "  loss = F.nll_loss(output.view(-1, 45),\n",
        "                          sm.contiguous().view(-1),\n",
        "                          ignore_index=PAD)\n",
        "  total_loss += loss.item()\n",
        "  batch_bar.set_postfix(\n",
        "            loss=f\"{float(total_loss / (b + 1))}\")\n",
        "  batch_bar.update()\n",
        "batch_bar.close()\n",
        "print(total_loss / len(test_loader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o-9kf4U35nZ2"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.insert(0,'/content/11785FinalProject/transformer_xl')\n",
        "\n",
        "import data_utils\n",
        "from mem_transformer import MemTransformerLM \n",
        "\n",
        "sys.path.insert(0,'/content/11785FinalProject/transformer_xl/utils')\n",
        "from proj_adaptive_softmax import ProjectedAdaptiveLogSoftmax\n",
        "#sys.path.insert(0,'/content/drive/MyDrive/Colab Notebooks/11785FinalProject/transformer_xl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uJWXYTwzN_03"
      },
      "outputs": [],
      "source": [
        "B = 4\n",
        "tgt_len, mem_len, ext_len = 36, 36, 0\n",
        "data_len = tgt_len * 20\n",
        "n_token = 45\n",
        "device = torch.device(\"cuda\" if \"cuda\" else \"cpu\")\n",
        "n_layer = 4\n",
        "n_rel_layer = 4\n",
        "n_head = 2\n",
        "d_head = 2\n",
        "d_model = 200\n",
        "d_embed = 200\n",
        "d_inner = 200\n",
        "dropout = 0.0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qfv-VCRRBMAE"
      },
      "outputs": [],
      "source": [
        "div_val = [1, 2]\n",
        "\n",
        "cutoffs = [n_token // 2]\n",
        "tie_projs = [False] + [True] * len(cutoffs)\n",
        "\n",
        "crit = ProjectedAdaptiveLogSoftmax(n_token, d_embed, d_model, \n",
        "                                                    cutoffs, div_val=div_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TU8VPrs7HBBX"
      },
      "outputs": [],
      "source": [
        "model = MemTransformerLM(n_token, n_layer, n_head,\n",
        "                            d_model, d_head, d_inner, dropout,\n",
        "                            dropatt=dropout, tie_weight=True, \n",
        "                            d_embed=d_embed, div_val=div_val[0], \n",
        "                            tie_projs=tie_projs, pre_lnorm=True,\n",
        "                            tgt_len=tgt_len, ext_len=ext_len, mem_len=mem_len, \n",
        "                            cutoffs=cutoffs, attn_type=0).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jMOxDwz4Juxu"
      },
      "outputs": [],
      "source": [
        "mems = tuple()\n",
        "for idx, (inp, tgt, seqlen) in enumerate(train_loader):\n",
        "                # print('batch {}'.format(idx))\n",
        "    \n",
        "\n",
        "from tqdm import tqdm\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "for b in range(5):\n",
        "  batch_bar = tqdm(total=len(train_loader), dynamic_ncols=True, leave=False, position=0, desc='Train') \n",
        "  total_loss = 0.0\n",
        "  for i, sm in enumerate(train_loader):\n",
        "    # if sm is None:\n",
        "    #   continue\n",
        "    sm = torch.t(sm.cuda()) # (T,B)\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    with torch.cuda.amp.autocast():\n",
        "      out = model(inp, tgt, *mems)\n",
        "      mems = out[1:]\n",
        "      output = out[0]\n",
        "      loss = crit(output.view(-1, output.size(-1)), tgt.flatten())\n",
        "      loss = loss.view(tgt.size(0), -1)\n",
        "      loss = loss.float().mean().type_as(loss)\n",
        "      total_loss += float(loss)\n",
        "    # print(float(loss))\n",
        "    batch_bar.set_postfix(\n",
        "            loss=f\"{float(total_loss / (i + 1))}\")\n",
        "    scaler.scale(loss).backward()\n",
        "    scaler.step(optimizer)\n",
        "    scaler.update()\n",
        "    # scheduler.step()\n",
        "    batch_bar.update()\n",
        "  batch_bar.close()\n",
        "  print(\"Epoch {}/{}: Train Loss {:.04f}\".format(\n",
        "        b + 1,\n",
        "        b,\n",
        "        float(total_loss / len(train_loader))))\n",
        "  torch.save({'epoch': 5,\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "        }, '/content/11785FinalProject/notebooks/project.pth')\n",
        "                "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qSE1N023d5hq"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "chenyu_train.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}