{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "eval.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "import os\n",
        "import pickle\n",
        "import argparse\n",
        "from collections import defaultdict\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import gzip\n",
        "import shutil\n",
        "import spacy \n",
        "import pandas as pd \n",
        "from tqdm import tqdm\n",
        "from collections import Counter\n",
        "import kora.install.rdkit\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import Draw, MolFromSmiles, MolToSmiles"
      ],
      "metadata": {
        "id": "25PMxgq3Bc2e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = torch.load('/content/drive/MyDrive/project_best.pth')\n",
        "model.load_state_dict(checkpoint['model_state_dict'])s"
      ],
      "metadata": {
        "id": "GF9IQbEDBYnM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hZzzS1icBNhN"
      },
      "outputs": [],
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "def eval_mlp(X, y, rate, n_repeats):\n",
        "    auc = np.empty(n_repeats)\n",
        "    for i in range(n_repeats):\n",
        "        clf = MLPClassifier(max_iter=1000)\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1-rate, stratify=y)\n",
        "        clf.fit(X_train, y_train)\n",
        "        y_score = clf.predict_proba(X_test)\n",
        "        auc[i] = roc_auc_score(y_test, y_score[:,1])\n",
        "    res = {}\n",
        "    res['auc mean'] = np.mean(auc)\n",
        "    res['auc std'] = np.mean(np.std(auc, axis=0))\n",
        "    return res\n",
        "\n",
        "def get_inputs(sm):\n",
        "    seq_len = 220\n",
        "    sm = sm.split()\n",
        "    if len(sm) > 218:\n",
        "        sm = sm[:109]+sm[-109:]\n",
        "    ids = [vocab.word_dict.get(token, unk_index) for token in sm]\n",
        "    ids = [sos_index] + ids + [eos_index]\n",
        "    seg = [1] * len(ids)\n",
        "    padding = [pad_index] * (seq_len - len(ids))\n",
        "    ids.extend(padding)\n",
        "    seg.extend(padding)\n",
        "    return ids, seg\n",
        "\n",
        "def get_array(smiles):\n",
        "    x_id, x_seg = [], []\n",
        "    for sm in smiles:\n",
        "        a,b = get_inputs(sm)\n",
        "        x_id.append(a)\n",
        "        x_seg.append(b)\n",
        "    return torch.tensor(x_id), torch.tensor(x_seg)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fs = [('/content/drive/MyDrive/BBBP.csv', 'p_np', 'smiles'), ('/content/drive/MyDrive/HIV.csv', 'HIV_active', 'smiles'), ('/content/drive/MyDrive/bace.csv', 'Class', 'mol')]\n",
        "for f in fs:\n",
        "    model.eval()\n",
        "    pad_index = 0\n",
        "    unk_index = 1\n",
        "    eos_index = 2\n",
        "    sos_index = 3\n",
        "    mask_index = 4\n",
        "    df = pd.read_csv(f[0])\n",
        "    rates = 2**np.arange(7)/80\n",
        "    x_split = [split(sm) for sm in df[f[2]].values]\n",
        "    xid, _ = get_array(x_split)\n",
        "    X = model.encode(torch.t(xid).cuda())\n",
        "    mean_score = np.zeros(len(rates))\n",
        "    print(X.shape)\n",
        "    for i, rate in enumerate(rates):\n",
        "        score_dic = eval_mlp(X, df[f[1]].values, rate, 20)\n",
        "        mean_score[i] = score_dic['auc mean']\n",
        "        print(rate, score_dic)\n",
        "    \n",
        "    print(np.mean(mean_score))"
      ],
      "metadata": {
        "id": "6YmtM0VIBROc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}